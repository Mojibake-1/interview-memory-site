[
  {
    "id": "llm_prompt_template",
    "term": "Prompt 模板化",
    "category": "LLM 与摘要结构化",
    "core": "Prompt 模板化把可变信息与固定规则分离，能显著降低多人协作时的提示词漂移。",
    "boundary": "每次临场重写 prompt 会让输出风格无法稳定复现。",
    "signal": "当同一任务由不同人维护或需要长期运行时，应把 prompt 模板产品化。",
    "action": "把模板拆成“角色约束 + 输入槽位 + 输出格式”；变量统一由程序填充并版本管理。",
    "aliases": [
      "prompt",
      "模板"
    ]
  },
  {
    "id": "structured_output",
    "term": "结构化输出（JSON）",
    "category": "LLM 与摘要结构化",
    "core": "结构化输出要求模型返回可机读格式（如 JSON），让结果可校验、可存储、可下游消费。",
    "boundary": "只返回自然语言段落会增加解析歧义，后续自动化链路不稳定。",
    "signal": "当结果需要进入数据库、工作流节点或 API 时，应强制结构化输出。",
    "action": "给出 JSON schema 示例并做解析校验；解析失败时触发重试或降级策略。",
    "aliases": [
      "JSON",
      "structured output"
    ]
  },
  {
    "id": "summary_length_limit",
    "term": "摘要长度约束",
    "category": "LLM 与摘要结构化",
    "core": "摘要长度约束是在信息保真与阅读成本之间做预算分配，避免“太短丢信息、太长没价值”。",
    "boundary": "只给字数上限不定义优先级，会导致模型删掉关键结论保留次要细节。",
    "signal": "当业务方反馈“摘要看不出重点”时，通常不是模型差，而是长度与优先级规则缺失。",
    "action": "先定义必保留字段（结论/风险/下一步），再设字数区间并用自动检查拦截超长。",
    "aliases": [
      "长度",
      "摘要"
    ]
  },
  {
    "id": "rule_plus_llm",
    "term": "规则 + LLM 双层策略",
    "category": "LLM 与摘要结构化",
    "core": "规则 + LLM 双层策略让确定性逻辑由规则处理，模糊理解交给模型，兼顾稳定性和泛化能力。",
    "boundary": "把所有判断都压给模型，会在边界条件下出现不可预测波动。",
    "signal": "当任务里既有硬规则（格式、黑名单）又有语义判断时，双层策略最稳。",
    "action": "先跑规则引擎筛选，再把剩余样本交给 LLM；输出后再做规则二次校验。",
    "aliases": [
      "双层",
      "规则+AI"
    ]
  },
  {
    "id": "hallucination_guard",
    "term": "幻觉防护",
    "category": "LLM 与摘要结构化",
    "core": "幻觉防护的核心是“让模型在不确定时少编造”，通过证据约束和拒答机制控制风险。",
    "boundary": "只追求回答完整度而不约束证据来源，会放大错误信息传播。",
    "signal": "当任务涉及事实查询、政策解读或高风险决策时，必须启用防幻觉策略。",
    "action": "要求引用来源或返回“未知”；未检索到证据时触发拒答模板而非强行生成。",
    "aliases": [
      "幻觉",
      "真实性"
    ]
  },
  {
    "id": "uncertainty_mark",
    "term": "不确定性标记",
    "category": "LLM 与摘要结构化",
    "core": "不确定性标记把“置信不足”显式展示给用户，帮助下游做人工复核决策。",
    "boundary": "把低把握答案伪装成确定结论，会直接损害系统可信度。",
    "signal": "当输入噪声大、信息缺失或跨领域问题多时，应在输出中附置信等级。",
    "action": "输出增加 `confidence` 字段与“需复核原因”；低置信结果默认进入人工审核队列。",
    "aliases": [
      "置信度",
      "复核"
    ]
  },
  {
    "id": "redaction",
    "term": "敏感信息脱敏",
    "category": "LLM 与摘要结构化",
    "core": "脱敏是在进入模型前移除个人信息和敏感字段，满足隐私合规和最小数据原则。",
    "boundary": "把原始用户数据直接喂给第三方模型，可能触发合规与合同风险。",
    "signal": "处理工单、聊天记录、简历等含 PII 数据时，脱敏应成为默认步骤。",
    "action": "在预处理阶段替换手机号/邮箱/身份证等字段，必要时仅保留哈希或掩码值。",
    "aliases": [
      "脱敏",
      "redaction"
    ]
  },
  {
    "id": "model_fallback",
    "term": "模型降级策略",
    "category": "LLM 与摘要结构化",
    "core": "模型降级策略用于在主模型不可用或成本超限时维持服务连续性。",
    "boundary": "没有降级预案会让一次供应商故障直接演变成全站不可用。",
    "signal": "出现超时、限流或成本异常波动时，系统应自动切换到备选模型。",
    "action": "定义主备模型路由规则，按错误类型触发 fallback；切换时记录质量差异和恢复时点。",
    "aliases": [
      "fallback",
      "降级"
    ]
  },
  {
    "id": "tool_calling",
    "term": "工具调用（Tool Use）",
    "category": "LLM 与摘要结构化",
    "core": "工具调用让模型把“会说”变成“会做”，通过函数接口访问检索、数据库或业务系统。",
    "boundary": "不限制工具权限会把语言模型变成高风险执行入口。",
    "signal": "当问题需要实时数据或外部计算时，纯文本回答通常不够，需启用 tool use。",
    "action": "为每个工具定义输入 schema 和权限边界；执行前做参数校验，执行后回写结构化结果。",
    "aliases": [
      "function calling",
      "tool use"
    ]
  }
]
