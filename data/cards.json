[
  {
    "id": "outcome_driven",
    "term": "成果导向（Show, don’t tell）",
    "category": "岗位与目标",
    "core": "成果导向的核心是先给证据再讲方法，让对方先确认“你确实做成过”。",
    "boundary": "只强调学习热情却拿不出产出物，难以说服招聘方承担试错成本。",
    "signal": "自我介绍、项目讲解和追问细节阶段，都应该优先抛出结果证据。",
    "action": "每个项目准备一组证据：演示链接、关键指标、故障处理案例。",
    "aliases": [
      "show dont tell",
      "成果导向",
      "可交付"
    ]
  },
  {
    "id": "credibility_over_depth",
    "term": "可信度优先于科班深度",
    "category": "岗位与目标",
    "core": "岗位匹配优先看可交付可信度，其次才是理论深度，尤其在工程执行型岗位。",
    "boundary": "把“懂概念”当“能落地”会在试用期迅速暴露落差。",
    "signal": "当岗位描述强调上线、维护、协作节奏时，可信交付记录更重要。",
    "action": "回答时用“场景-动作-结果”结构，优先讲真实落地案例而非泛泛原理。",
    "aliases": [
      "可信度",
      "上手",
      "落地"
    ]
  },
  {
    "id": "jd_alignment",
    "term": "JD 关键词对齐",
    "category": "岗位与目标",
    "core": "JD 对齐是把招聘需求拆成能力清单，并逐项给出对应证据，降低不确定性。",
    "boundary": "只说“我都可以学”而不对齐关键关键词，简历会被快速过滤。",
    "signal": "投递前和面试前复盘 JD 是提升命中率的低成本高收益动作。",
    "action": "把 JD 列成表格：需求、你的证据、风险点、补齐计划。",
    "aliases": [
      "JD",
      "对齐",
      "匹配"
    ]
  },
  {
    "id": "business_context",
    "term": "业务语境对齐",
    "category": "岗位与目标",
    "core": "业务语境对齐要求你用公司场景解释技术选择，证明你关注的是业务结果而非工具炫技。",
    "boundary": "脱离业务讲技术方案，会被认为缺少产品意识。",
    "signal": "被问“你能给我们带来什么价值”时，本质是在考察业务语境理解。",
    "action": "提前研究公司产品流程，准备 1-2 个针对性优化建议并说明收益。",
    "aliases": [
      "业务语境",
      "场景对齐"
    ]
  },
  {
    "id": "iteration_mindset",
    "term": "迭代思维",
    "category": "岗位与目标",
    "core": "迭代思维强调先交付可用版本，再通过反馈快速修正，而不是一次性追求完美。",
    "boundary": "把 MVP 理解成“粗糙上线”而不设后续迭代计划，会透支信任。",
    "signal": "需求不确定、时间紧张时，迭代策略比大设计更有效。",
    "action": "定义每轮迭代目标、验收标准和回顾节点，确保每周都有可见改进。",
    "aliases": [
      "迭代",
      "MVP"
    ]
  },
  {
    "id": "engineering_priority",
    "term": "工程化优先",
    "category": "岗位与目标",
    "core": "工程化优先指先搭建可重复、可监控、可回滚的基础能力，再追求功能堆叠。",
    "boundary": "先写功能后补工程治理，后期维护成本会成倍增长。",
    "signal": "系统开始被多人使用或进入长期维护阶段，工程化就是首要任务。",
    "action": "优先补测试、日志、配置管理和部署脚本；功能开发遵循同一质量门槛。",
    "aliases": [
      "工程化",
      "稳定性"
    ]
  },
  {
    "id": "value_chain",
    "term": "价值闭环",
    "category": "岗位与目标",
    "core": "价值闭环要求把“输入->处理->输出->反馈”串起来，证明你的工作最终影响了业务指标。",
    "boundary": "只展示中间过程而没有结果反馈，价值链条是不完整的。",
    "signal": "面试官追问“这件事最后改变了什么”时，需要给出闭环答案。",
    "action": "陈述项目时固定补一句：谁使用了结果、结果如何被验证、下一步如何迭代。",
    "aliases": [
      "价值闭环",
      "业务输出"
    ]
  },
  {
    "id": "self_positioning",
    "term": "面试人设定位",
    "category": "岗位与目标",
    "core": "面试人设定位是持续输出一致职业信号，例如“能快速落地并守住稳定性”。",
    "boundary": "每轮表达重点都变，会让面试官难以形成清晰印象。",
    "signal": "多轮面试跨角色沟通时，稳定定位能提升评价一致性。",
    "action": "确定 2-3 个核心标签，并为每个标签准备一个可验证案例。",
    "aliases": [
      "人设",
      "定位"
    ]
  },
  {
    "id": "demo_closure",
    "term": "可演示 Demo 闭环",
    "category": "交付物与证据",
    "core": "可演示 Demo 闭环强调“输入可见、处理可追踪、结果可验证”，让能力从口头描述变成可检查事实。",
    "boundary": "只有代码仓库没有运行路径，面试官无法判断你是否真正跑通过全链路。",
    "signal": "当对方追问“你到底做成了什么”时，Demo 是最直接的说服材料。",
    "action": "准备一条固定演示脚本：启动命令、样例输入、输出截图、失败兜底说明。",
    "aliases": [
      "demo",
      "闭环"
    ]
  },
  {
    "id": "readme_delivery",
    "term": "README 交付说明",
    "category": "交付物与证据",
    "core": "README 交付说明是项目的操作手册，决定别人能否在 10 分钟内跑起来。",
    "boundary": "只写项目背景不写启动步骤，会让交付文件失去使用价值。",
    "signal": "代码准备交接、开源或面试展示时，README 质量直接影响可信度。",
    "action": "按“环境准备 -> 启动命令 -> 配置说明 -> 常见问题”四段编写，并附最小示例。",
    "aliases": [
      "README",
      "交付"
    ]
  },
  {
    "id": "architecture_diagram",
    "term": "架构图",
    "category": "交付物与证据",
    "core": "架构图用于把系统边界和数据流一眼说清，降低跨角色沟通成本。",
    "boundary": "画成装饰图而不标注关键组件、输入输出和依赖关系，图再美也难落地。",
    "signal": "需要解释方案取舍、排障路径或扩展计划时，架构图是首选表达工具。",
    "action": "图上至少标出触发器、处理节点、存储、通知链路和失败分支。",
    "aliases": [
      "架构图",
      "模块划分"
    ]
  },
  {
    "id": "workflow_screenshot",
    "term": "工作流截图证据",
    "category": "交付物与证据",
    "core": "工作流截图是“流程已配置并实际运行”的轻量证据，尤其适用于低代码平台项目。",
    "boundary": "只展示编辑界面不展示执行结果，无法证明流程真的可用。",
    "signal": "面试远程演示受限、无法现场登录环境时，截图证据非常关键。",
    "action": "保留三类截图：流程拓扑、成功执行记录、失败告警记录。",
    "aliases": [
      "截图",
      "证据"
    ]
  },
  {
    "id": "failure_alert_proof",
    "term": "失败告警证明",
    "category": "交付物与证据",
    "core": "失败告警证明体现的是系统可运营性，说明你不仅能跑通 happy path，还考虑了故障可感知。",
    "boundary": "仅展示成功结果会让系统看起来脆弱，缺少生产意识。",
    "signal": "当面试官关注稳定性和值班能力时，告警证据是高分项。",
    "action": "准备一次可控失败演示：触发错误 -> 收到告警 -> 定位并恢复。",
    "aliases": [
      "失败告警",
      "稳定性证明"
    ]
  },
  {
    "id": "one_page_plan",
    "term": "一页落地方案",
    "category": "交付物与证据",
    "core": "一页落地方案用于在有限时间内说明目标、路径、风险和里程碑，帮助决策快速推进。",
    "boundary": "方案写成长文档却没有优先级和交付节奏，实际执行会失焦。",
    "signal": "项目启动会、面试方案题或跨团队协作前，通常需要一页版方案。",
    "action": "固定结构：目标、现状、方案、风险、排期、验收标准，控制在 1 页内。",
    "aliases": [
      "一页纸",
      "方案"
    ]
  },
  {
    "id": "recorded_demo",
    "term": "1 分钟录屏备份",
    "category": "交付物与证据",
    "core": "1 分钟录屏是现场演示的保险丝，保证网络或环境异常时仍能完整呈现成果。",
    "boundary": "完全依赖现场演示，一旦环境抖动会直接损失表达机会。",
    "signal": "远程面试、设备限制或账号权限不稳定时，录屏备份非常必要。",
    "action": "录屏覆盖启动、关键操作、结果页和日志；文件名带版本和日期，方便快速检索。",
    "aliases": [
      "录屏",
      "备份"
    ]
  },
  {
    "id": "fact_list",
    "term": "事实清单",
    "category": "交付物与证据",
    "core": "事实清单把项目中的可验证事实集中列出，避免讲述时混入模糊表述。",
    "boundary": "全靠记忆即兴发挥容易前后矛盾，降低可信度。",
    "signal": "准备面试复盘、写项目总结或回答深挖问题前，先整理事实清单最稳。",
    "action": "每条事实包含：时间、动作、证据链接、结果指标；优先保留可截图/可日志佐证项。",
    "aliases": [
      "事实清单",
      "可验证"
    ]
  },
  {
    "id": "trigger",
    "term": "触发器（Trigger）",
    "category": "自动化闭环架构",
    "core": "Trigger 定义流程何时启动，是自动化系统节奏控制的起点。",
    "boundary": "触发条件模糊会导致漏触发或重复触发。",
    "signal": "任务需要稳定周期或事件驱动时，首先设计 trigger 策略。",
    "action": "明确触发来源、频率、去重键；触发日志必须可审计。",
    "aliases": [
      "trigger",
      "schedule",
      "webhook"
    ]
  },
  {
    "id": "collector",
    "term": "采集器（Collector）",
    "category": "自动化闭环架构",
    "core": "Collector 负责可靠采集原始数据，目标是完整性和可追溯性。",
    "boundary": "采集阶段直接做重业务加工会放大耦合。",
    "signal": "外部数据源不稳定时，collector 质量决定后续是否有数据可用。",
    "action": "采集和加工分离；采集结果先落原始快照并记录来源元信息。",
    "aliases": [
      "collector",
      "采集"
    ]
  },
  {
    "id": "parser",
    "term": "解析器（Parser）",
    "category": "自动化闭环架构",
    "core": "Parser 把原始数据转为结构化字段，是后续去重、分类、报表的基础。",
    "boundary": "解析规则散落在多处会造成行为不一致。",
    "signal": "字段提取错误率上升时，优先检查 parser 规则版本。",
    "action": "为解析规则建立单测样例库；变更后先回放历史样本验证。",
    "aliases": [
      "parser",
      "解析"
    ]
  },
  {
    "id": "dedup",
    "term": "去重模块（Dedup）",
    "category": "自动化闭环架构",
    "core": "Dedup 通过业务主键或内容指纹消除重复记录，避免重复处理和重复通知。",
    "boundary": "仅凭时间窗口去重会漏掉跨窗口重复。",
    "signal": "出现同一事件多次推送时，说明去重键设计不充分。",
    "action": "定义稳定去重键（source_id/hash）；写入前先查重并记录命中率。",
    "aliases": [
      "去重",
      "dedup"
    ]
  },
  {
    "id": "summarizer",
    "term": "摘要器（Summarizer）",
    "category": "自动化闭环架构",
    "core": "Summarizer 把冗长信息压缩为可决策摘要，重点是保留结论与风险。",
    "boundary": "只追求短文本会丢失关键上下文。",
    "signal": "输入信息密度高、接收方决策时间短时，摘要能力价值最大。",
    "action": "输出固定结构：结论、依据、风险、建议动作；长度和字段做自动校验。",
    "aliases": [
      "摘要",
      "summarizer"
    ]
  },
  {
    "id": "classifier",
    "term": "分类器（Classifier）",
    "category": "自动化闭环架构",
    "core": "Classifier 对事件分级归类，帮助系统按优先级分配处理资源。",
    "boundary": "分类标签定义含糊会导致路由和告警策略失准。",
    "signal": "任务量增长后，需要自动分流到不同处理队列。",
    "action": "先定义标签字典和判定规则，保留人工纠正入口并回流训练样本。",
    "aliases": [
      "分类",
      "标签"
    ]
  },
  {
    "id": "reporter",
    "term": "报告器（Reporter）",
    "category": "自动化闭环架构",
    "core": "Reporter 负责把处理结果组织成面向人或系统的可消费报告。",
    "boundary": "报告只堆数据不提结论，读者难以行动。",
    "signal": "周期汇报或跨团队同步场景中，reporter 决定信息传达效率。",
    "action": "报告模板固定“摘要-明细-异常-下一步”，支持导出链接和版本记录。",
    "aliases": [
      "report",
      "日报"
    ]
  },
  {
    "id": "notifier",
    "term": "通知器（Notifier）",
    "category": "自动化闭环架构",
    "core": "Notifier 把关键信号按渠道和优先级送达正确的人，确保事件被及时感知。",
    "boundary": "通知策略不分级会造成噪音和告警疲劳。",
    "signal": "系统已具备检测能力但响应仍慢时，通常是通知链路设计问题。",
    "action": "按严重级别映射不同通道和频率；通知内容附操作入口。",
    "aliases": [
      "notify",
      "推送"
    ]
  },
  {
    "id": "scheduler",
    "term": "调度器（Scheduler）",
    "category": "自动化闭环架构",
    "core": "Scheduler 管理任务执行顺序和频率，是稳定吞吐和资源利用的关键组件。",
    "boundary": "无调度策略的并发执行会造成资源争抢和雪崩。",
    "signal": "任务数量增长、执行时长不均时，需要调度策略兜底。",
    "action": "为任务设置优先级、并发上限和超时；积压超过阈值自动告警。",
    "aliases": [
      "调度",
      "cron",
      "schedule"
    ]
  },
  {
    "id": "alerting",
    "term": "告警链路（Alerting）",
    "category": "自动化闭环架构",
    "core": "告警链路把异常转换为可执行动作，核心是准确、及时、可追踪。",
    "boundary": "阈值过敏会制造噪声，阈值过宽会漏报。",
    "signal": "值班响应慢或误报多时，应先优化 alerting 规则。",
    "action": "按故障级别配置不同阈值和升级路径；告警必须包含定位线索。",
    "aliases": [
      "alert",
      "告警"
    ]
  },
  {
    "id": "idempotency",
    "term": "幂等性（Idempotency）",
    "category": "自动化闭环架构",
    "core": "幂等性保证同一请求重复执行结果一致，是重试和容灾的基础。",
    "boundary": "没有幂等键就重试，容易产生重复扣费或重复通知。",
    "signal": "系统涉及重试、消息重投或网络抖动时，幂等必须前置设计。",
    "action": "为写操作引入幂等键并持久化状态；重复请求直接返回首次结果。",
    "aliases": [
      "幂等",
      "idempotent"
    ]
  },
  {
    "id": "retry_backoff",
    "term": "重试与退避（Retry + Backoff）",
    "category": "自动化闭环架构",
    "core": "重试与退避用于提升短暂故障下的成功率，同时避免集中重试压垮下游。",
    "boundary": "固定间隔重试容易形成请求风暴。",
    "signal": "第三方 API 偶发超时或 5xx 时，退避重试是有效手段。",
    "action": "使用指数退避 + 随机抖动，设置最大重试次数和总超时预算。",
    "aliases": [
      "retry",
      "backoff"
    ]
  },
  {
    "id": "timeout",
    "term": "超时控制（Timeout）",
    "category": "自动化闭环架构",
    "core": "超时控制用于给每步操作设上限，防止单点阻塞拖垮全链路。",
    "boundary": "默认无超时会导致任务长期挂起且难以恢复。",
    "signal": "队列积压和任务卡死常与超时配置缺失相关。",
    "action": "按阶段设置连接/读取/任务总超时；超时后记录上下文并走补偿。",
    "aliases": [
      "timeout",
      "超时"
    ]
  },
  {
    "id": "rate_limit",
    "term": "限速（Rate Limit）",
    "category": "自动化闭环架构",
    "core": "限速通过控制请求速率保护本系统和下游服务，平衡吞吐与稳定。",
    "boundary": "不设限速在流量尖峰时容易触发对方封禁。",
    "signal": "接口频繁返回 429 或资源突增时，需要立即启用限速。",
    "action": "按租户或任务类型配置令牌桶；超限请求排队或降级。",
    "aliases": [
      "限频",
      "rate limit"
    ]
  },
  {
    "id": "config_driven",
    "term": "配置化（Config-driven）",
    "category": "自动化闭环架构",
    "core": "配置化让行为参数可调整而无需改代码，提升迭代速度和运营灵活性。",
    "boundary": "把规则硬编码在逻辑里，每次改策略都要发版。",
    "signal": "规则变动频繁、不同客户差异明显时，配置化优先。",
    "action": "把阈值、路由、模板抽成配置文件；配置变更走校验和灰度发布。",
    "aliases": [
      "配置化",
      "config"
    ]
  },
  {
    "id": "source_adapter",
    "term": "数据源适配器（Source Adapter）",
    "category": "自动化闭环架构",
    "core": "数据源适配器把外部差异封装在边界层，核心流程只处理统一内部模型。",
    "boundary": "在核心逻辑里写大量 source if/else 会迅速失控。",
    "signal": "新增数据源成本越来越高时，说明缺少 adapter 抽象。",
    "action": "定义统一接口（fetch/normalize/healthcheck），每个源单独实现并可独立测试。",
    "aliases": [
      "adapter",
      "source"
    ]
  },
  {
    "id": "rss_first",
    "term": "RSS 优先",
    "category": "采集与合规",
    "core": "RSS 优先意味着先使用公开、稳定、低侵扰的数据接口，降低维护和合规风险。",
    "boundary": "直接抓网页而忽略官方订阅源，会增加解析脆弱性。",
    "signal": "内容站点提供 RSS 时，通常应优先走 RSS 采集。",
    "action": "先检查站点 feed 地址；采集失败再考虑页面抓取作为补充。",
    "aliases": [
      "rss",
      "公开源"
    ]
  },
  {
    "id": "public_api_first",
    "term": "公开 API 优先",
    "category": "采集与合规",
    "core": "公开 API 优先可获得更稳定字段和明确调用规则，长期成本更低。",
    "boundary": "绕过 API 强抓页面可能违反条款且易失效。",
    "signal": "第三方平台既有 API 又有网页时，先评估 API 覆盖度。",
    "action": "阅读 API 文档、速率限制和授权要求；不足部分再设计补采方案。",
    "aliases": [
      "API",
      "公开接口"
    ]
  },
  {
    "id": "robots_txt",
    "term": "robots.txt",
    "category": "采集与合规",
    "core": "robots.txt 提供采集访问边界参考，是合规采集的基础信号之一。",
    "boundary": "无视 robots 规则会增加封禁和法律风险。",
    "signal": "接入新站点前应先检查 robots 策略和允许路径。",
    "action": "程序启动时拉取并缓存 robots 规则；禁止路径直接跳过。",
    "aliases": [
      "robots",
      "合规"
    ]
  },
  {
    "id": "tos_respect",
    "term": "遵守 ToS",
    "category": "采集与合规",
    "core": "遵守 ToS 是商业采集合规底线，决定项目是否能长期持续运营。",
    "boundary": "“技术上能抓”不代表“法律上可用”。",
    "signal": "面向企业交付或对外发布产品时，ToS 合规审查不可省。",
    "action": "对每个数据源记录 ToS 摘要和使用边界；高风险源走法务确认。",
    "aliases": [
      "ToS",
      "条款"
    ]
  },
  {
    "id": "user_agent",
    "term": "User-Agent 声明",
    "category": "采集与合规",
    "core": "User-Agent 声明用于标识采集程序身份，提升透明度并便于站点方联系。",
    "boundary": "伪装浏览器身份规避限制可能引发信任和合规问题。",
    "signal": "采集请求被限制或需要与站点运营沟通时，规范 UA 很关键。",
    "action": "UA 包含项目名、版本和联系邮箱；在请求频率上保持克制。",
    "aliases": [
      "header",
      "UA"
    ]
  },
  {
    "id": "cache_policy",
    "term": "缓存策略",
    "category": "采集与合规",
    "core": "缓存策略通过减少重复请求降低源站压力，同时提升采集效率。",
    "boundary": "无缓存会造成不必要流量；缓存过期策略错误会导致数据陈旧。",
    "signal": "抓取频率高且内容更新周期可预估时，应设计缓存策略。",
    "action": "结合 ETag/Last-Modified 做条件请求；按数据类型设置 TTL。",
    "aliases": [
      "缓存",
      "cache"
    ]
  },
  {
    "id": "privacy_guard",
    "term": "隐私数据避让",
    "category": "采集与合规",
    "core": "隐私数据避让要求最小化采集和存储个人信息，降低合规和伦理风险。",
    "boundary": "“先采了再说”会把系统置于被动治理状态。",
    "signal": "涉及用户评论、联系方式等数据时，隐私策略必须前置。",
    "action": "定义敏感字段清单并默认脱敏；无业务必要字段不入库。",
    "aliases": [
      "隐私",
      "PII"
    ]
  },
  {
    "id": "compliance_statement",
    "term": "合规声明",
    "category": "采集与合规",
    "core": "合规声明用于明确数据来源、用途、保留策略和用户权利，提升透明度和信任。",
    "boundary": "没有公开声明会让外部难以判断项目边界。",
    "signal": "项目对外展示或商业化前，需准备简明合规说明。",
    "action": "文档写清采集范围、更新频率、删除机制和联系方式，并定期更新版本。",
    "aliases": [
      "合规声明",
      "README"
    ]
  },
  {
    "id": "site_change_fallback",
    "term": "站点结构变更兜底",
    "category": "采集与合规",
    "core": "站点结构变更兜底用于在页面改版时保持服务连续，减少中断影响。",
    "boundary": "把解析规则写死且无监控，会在改版后长时间静默失败。",
    "signal": "目标站点改版频繁时，必须设计多策略解析与失败告警。",
    "action": "主解析失败后切换备选选择器或降级数据源，并触发人工检查任务。",
    "aliases": [
      "selector",
      "结构变更"
    ]
  },
  {
    "id": "source_failover",
    "term": "数据源降级策略",
    "category": "采集与合规",
    "core": "数据源降级策略在主源不可用时切换备选来源，保障关键功能不中断。",
    "boundary": "只有单数据源会形成不可控单点风险。",
    "signal": "主源偶发超时、封禁或维护时，降级策略决定服务韧性。",
    "action": "定义主备源优先级和切换条件；切换事件写入日志并通知值班。",
    "aliases": [
      "降级",
      "failover"
    ]
  },
  {
    "id": "csv_storage",
    "term": "CSV 存储",
    "category": "数据处理与去重",
    "core": "CSV 存储轻量、通用，适合中小规模数据交换与初期落地。",
    "boundary": "把 CSV 当高并发数据库使用会出现读写冲突和性能瓶颈。",
    "signal": "原型阶段或跨工具导入导出需求明显时，CSV 是低门槛选择。",
    "action": "固定列顺序和编码（UTF-8）；写入前做字段清洗并加表头版本注释。",
    "aliases": [
      "csv"
    ]
  },
  {
    "id": "sqlite_storage",
    "term": "SQLite 存储",
    "category": "数据处理与去重",
    "core": "SQLite 提供单文件事务数据库能力，适合本地任务和轻量服务的数据持久化。",
    "boundary": "在高并发写场景强用 SQLite 会遇到锁竞争。",
    "signal": "需要比 CSV 更可靠的查询和约束，但又不想引入独立数据库服务时可选 SQLite。",
    "action": "为关键字段建索引和唯一约束；定期 `VACUUM` 并备份数据库文件。",
    "aliases": [
      "sqlite"
    ]
  },
  {
    "id": "unique_index",
    "term": "唯一索引",
    "category": "数据处理与去重",
    "core": "唯一索引通过数据库约束从源头防重，优于应用层“先查后写”的脆弱方案。",
    "boundary": "只在代码里判断重复，在并发下仍会写入脏数据。",
    "signal": "同一记录重复入库或重复通知时，应优先加唯一索引。",
    "action": "根据业务主键（如 source_id+date）建立 UNIQUE；冲突时采用 upsert 策略。",
    "aliases": [
      "unique",
      "索引"
    ]
  },
  {
    "id": "url_hash",
    "term": "URL 哈希",
    "category": "数据处理与去重",
    "core": "URL 哈希把长链接映射为固定长度键，便于去重和快速比较。",
    "boundary": "不做 URL 规范化就哈希，会把同一资源误判为不同记录。",
    "signal": "采集系统需要大量链接去重时，URL 哈希是常见基建手段。",
    "action": "先做规范化（去追踪参数、统一协议），再计算 hash 并持久化原始 URL 供追溯。",
    "aliases": [
      "hash",
      "url"
    ]
  },
  {
    "id": "timestamping",
    "term": "时间戳标准化",
    "category": "数据处理与去重",
    "core": "时间戳标准化确保跨系统数据可比较、可排序、可追踪。",
    "boundary": "混用本地时间和 UTC 会导致数据对齐混乱。",
    "signal": "多数据源合并或跨时区分析时，时间字段处理必须统一。",
    "action": "入库统一存 UTC ISO8601；展示层再按用户时区转换。",
    "aliases": [
      "timestamp",
      "UTC"
    ]
  },
  {
    "id": "data_cleaning",
    "term": "数据清洗",
    "category": "数据处理与去重",
    "core": "数据清洗用于处理缺失、异常、重复和格式不一致，决定下游分析可信度。",
    "boundary": "跳过清洗直接分析，得到的结论可能方向性错误。",
    "signal": "字段缺失率上升、统计结果异常波动时，优先检查清洗规则。",
    "action": "定义清洗流水线：去空值、标准化、异常值处理、去重；每步记录样本变化。",
    "aliases": [
      "清洗",
      "normalize"
    ]
  },
  {
    "id": "data_schema",
    "term": "数据字段规范（Schema）",
    "category": "数据处理与去重",
    "core": "Schema 规定字段名、类型和约束，是跨模块数据协作的共同语言。",
    "boundary": "字段随意增删改会让解析器和报表频繁崩溃。",
    "signal": "当数据需要跨团队或跨服务传递时，schema 先于功能开发。",
    "action": "用 JSON Schema 或表结构文档固化约束；变更走版本化和兼容窗口。",
    "aliases": [
      "schema",
      "字段规范"
    ]
  },
  {
    "id": "raw_snapshot",
    "term": "原始快照回放",
    "category": "数据处理与去重",
    "core": "原始快照回放保留“未经处理”的输入证据，便于复盘和规则回归测试。",
    "boundary": "只保存处理后结果，一旦规则有误无法还原现场。",
    "signal": "采集规则频繁迭代或数据争议较多时，快照回放价值极高。",
    "action": "按批次存原始 payload 并附采集时间；修规则后先对历史快照回放验证。",
    "aliases": [
      "回放",
      "snapshot"
    ]
  },
  {
    "id": "incremental_update",
    "term": "增量更新",
    "category": "数据处理与去重",
    "core": "增量更新只处理变化部分，能显著降低任务耗时和资源消耗。",
    "boundary": "每次全量重跑不仅慢，还容易触发重复写入和重复通知。",
    "signal": "数据规模增长导致窗口内跑不完时，应切换增量策略。",
    "action": "维护游标（时间戳/ID）；每次只拉取游标之后数据，成功后再推进游标。",
    "aliases": [
      "增量",
      "cursor"
    ]
  },
  {
    "id": "data_quality_check",
    "term": "数据质量校验",
    "category": "数据处理与去重",
    "core": "数据质量校验通过规则和指标持续监控数据健康，防止坏数据静默扩散。",
    "boundary": "只在入库时报错而无持续监控，异常会在下游才被发现。",
    "signal": "报表突变或模型效果下降时，往往先是数据质量出问题。",
    "action": "设置完整性、唯一性、范围合法性三类检查；异常时阻断下游并告警。",
    "aliases": [
      "质量",
      "校验"
    ]
  },
  {
    "id": "llm_prompt_template",
    "term": "Prompt 模板化",
    "category": "LLM 与摘要结构化",
    "core": "Prompt 模板化把可变信息与固定规则分离，能显著降低多人协作时的提示词漂移。",
    "boundary": "每次临场重写 prompt 会让输出风格无法稳定复现。",
    "signal": "当同一任务由不同人维护或需要长期运行时，应把 prompt 模板产品化。",
    "action": "把模板拆成“角色约束 + 输入槽位 + 输出格式”；变量统一由程序填充并版本管理。",
    "aliases": [
      "prompt",
      "模板"
    ]
  },
  {
    "id": "structured_output",
    "term": "结构化输出（JSON）",
    "category": "LLM 与摘要结构化",
    "core": "结构化输出要求模型返回可机读格式（如 JSON），让结果可校验、可存储、可下游消费。",
    "boundary": "只返回自然语言段落会增加解析歧义，后续自动化链路不稳定。",
    "signal": "当结果需要进入数据库、工作流节点或 API 时，应强制结构化输出。",
    "action": "给出 JSON schema 示例并做解析校验；解析失败时触发重试或降级策略。",
    "aliases": [
      "JSON",
      "structured output"
    ]
  },
  {
    "id": "summary_length_limit",
    "term": "摘要长度约束",
    "category": "LLM 与摘要结构化",
    "core": "摘要长度约束是在信息保真与阅读成本之间做预算分配，避免“太短丢信息、太长没价值”。",
    "boundary": "只给字数上限不定义优先级，会导致模型删掉关键结论保留次要细节。",
    "signal": "当业务方反馈“摘要看不出重点”时，通常不是模型差，而是长度与优先级规则缺失。",
    "action": "先定义必保留字段（结论/风险/下一步），再设字数区间并用自动检查拦截超长。",
    "aliases": [
      "长度",
      "摘要"
    ]
  },
  {
    "id": "rule_plus_llm",
    "term": "规则 + LLM 双层策略",
    "category": "LLM 与摘要结构化",
    "core": "规则 + LLM 双层策略让确定性逻辑由规则处理，模糊理解交给模型，兼顾稳定性和泛化能力。",
    "boundary": "把所有判断都压给模型，会在边界条件下出现不可预测波动。",
    "signal": "当任务里既有硬规则（格式、黑名单）又有语义判断时，双层策略最稳。",
    "action": "先跑规则引擎筛选，再把剩余样本交给 LLM；输出后再做规则二次校验。",
    "aliases": [
      "双层",
      "规则+AI"
    ]
  },
  {
    "id": "hallucination_guard",
    "term": "幻觉防护",
    "category": "LLM 与摘要结构化",
    "core": "幻觉防护的核心是“让模型在不确定时少编造”，通过证据约束和拒答机制控制风险。",
    "boundary": "只追求回答完整度而不约束证据来源，会放大错误信息传播。",
    "signal": "当任务涉及事实查询、政策解读或高风险决策时，必须启用防幻觉策略。",
    "action": "要求引用来源或返回“未知”；未检索到证据时触发拒答模板而非强行生成。",
    "aliases": [
      "幻觉",
      "真实性"
    ]
  },
  {
    "id": "uncertainty_mark",
    "term": "不确定性标记",
    "category": "LLM 与摘要结构化",
    "core": "不确定性标记把“置信不足”显式展示给用户，帮助下游做人工复核决策。",
    "boundary": "把低把握答案伪装成确定结论，会直接损害系统可信度。",
    "signal": "当输入噪声大、信息缺失或跨领域问题多时，应在输出中附置信等级。",
    "action": "输出增加 `confidence` 字段与“需复核原因”；低置信结果默认进入人工审核队列。",
    "aliases": [
      "置信度",
      "复核"
    ]
  },
  {
    "id": "redaction",
    "term": "敏感信息脱敏",
    "category": "LLM 与摘要结构化",
    "core": "脱敏是在进入模型前移除个人信息和敏感字段，满足隐私合规和最小数据原则。",
    "boundary": "把原始用户数据直接喂给第三方模型，可能触发合规与合同风险。",
    "signal": "处理工单、聊天记录、简历等含 PII 数据时，脱敏应成为默认步骤。",
    "action": "在预处理阶段替换手机号/邮箱/身份证等字段，必要时仅保留哈希或掩码值。",
    "aliases": [
      "脱敏",
      "redaction"
    ]
  },
  {
    "id": "model_fallback",
    "term": "模型降级策略",
    "category": "LLM 与摘要结构化",
    "core": "模型降级策略用于在主模型不可用或成本超限时维持服务连续性。",
    "boundary": "没有降级预案会让一次供应商故障直接演变成全站不可用。",
    "signal": "出现超时、限流或成本异常波动时，系统应自动切换到备选模型。",
    "action": "定义主备模型路由规则，按错误类型触发 fallback；切换时记录质量差异和恢复时点。",
    "aliases": [
      "fallback",
      "降级"
    ]
  },
  {
    "id": "tool_calling",
    "term": "工具调用（Tool Use）",
    "category": "LLM 与摘要结构化",
    "core": "工具调用让模型把“会说”变成“会做”，通过函数接口访问检索、数据库或业务系统。",
    "boundary": "不限制工具权限会把语言模型变成高风险执行入口。",
    "signal": "当问题需要实时数据或外部计算时，纯文本回答通常不够，需启用 tool use。",
    "action": "为每个工具定义输入 schema 和权限边界；执行前做参数校验，执行后回写结构化结果。",
    "aliases": [
      "function calling",
      "tool use"
    ]
  },
  {
    "id": "openclaw_gateway",
    "term": "Gateway（控制平面）",
    "category": "OpenClaw / Clawbot",
    "core": "Gateway 是控制平面的入口，负责统一鉴权、路由、限流和请求编排，决定系统能否稳定承接多渠道流量。",
    "boundary": "把网关仅当转发层会遗漏策略控制，后续在每个服务重复实现安全和流控逻辑。",
    "signal": "当接入来源增多（Web、IM、API）且行为不一致时，优先收敛到 Gateway 统一治理。",
    "action": "先定义统一请求 envelope（trace_id、tenant、auth）；在网关层落鉴权与限流，再下发到 agent。",
    "aliases": [
      "gateway"
    ]
  },
  {
    "id": "openclaw_channels",
    "term": "Channels（渠道入口）",
    "category": "OpenClaw / Clawbot",
    "core": "Channels 是外部入口适配层，核心任务是把不同平台消息标准化为内部统一事件。",
    "boundary": "直接在业务逻辑里写平台分支，会让每次新增渠道都改核心代码。",
    "signal": "同一指令在不同渠道表现不一致、消息字段映射混乱时，要先重构 channel adapter。",
    "action": "为每个渠道实现 `normalize -> validate -> emit` 三步，并保留原始 payload 便于回放。",
    "aliases": [
      "channel",
      "telegram"
    ]
  },
  {
    "id": "openclaw_skills",
    "term": "Skills（技能）",
    "category": "OpenClaw / Clawbot",
    "core": "Skills 是可组合能力单元，强调边界清晰、输入输出稳定，便于按任务动态编排。",
    "boundary": "把所有逻辑塞进单个大技能会降低复用率，也让权限控制变粗糙。",
    "signal": "当同类任务反复出现且处理步骤稳定时，应抽象成技能而不是复制 prompt。",
    "action": "每个 skill 明确：触发条件、参数 schema、副作用、失败返回；先做无状态版本再扩展。",
    "aliases": [
      "skills"
    ]
  },
  {
    "id": "openclaw_agent",
    "term": "Agent",
    "category": "OpenClaw / Clawbot",
    "core": "Agent 负责决策和执行闭环：理解意图、选择技能、调用工具、整理结果并反馈。",
    "boundary": "只让 agent 生成文本而不接入执行链路，会停留在“会说不会做”。",
    "signal": "当任务需要多步推理与外部操作联动时，应由 agent 统筹而不是脚本硬编码。",
    "action": "把 agent loop 固化为 `plan -> act -> observe -> revise`，并记录每步决策日志。",
    "aliases": [
      "agent"
    ]
  },
  {
    "id": "openclaw_onboard",
    "term": "onboard",
    "category": "OpenClaw / Clawbot",
    "core": "onboard 的目标是让新环境快速达到“可用、可测、可回滚”，不是只完成安装。",
    "boundary": "只发安装文档不做验收清单，通常会卡在权限、依赖和环境变量。",
    "signal": "新成员或新业务线首次接入时，onboard 质量决定首周交付速度。",
    "action": "准备 one-command 启动脚本 + 验收 checklist（健康检查、示例任务、日志可见、告警可达）。",
    "aliases": [
      "onboard"
    ]
  },
  {
    "id": "openclaw_doctor",
    "term": "doctor",
    "category": "OpenClaw / Clawbot",
    "core": "doctor 是自检入口，用于快速暴露依赖缺失、配置错误和权限问题，缩短故障定位路径。",
    "boundary": "出问题后再手工排查每一层会把恢复时间拉长。",
    "signal": "部署后无法正常响应、或“别人能跑我不能跑”时，先跑 doctor。",
    "action": "doctor 输出按严重级别分组：必修复/建议修复；失败项附可执行修复命令。",
    "aliases": [
      "doctor",
      "自检"
    ]
  },
  {
    "id": "openclaw_status",
    "term": "status",
    "category": "OpenClaw / Clawbot",
    "core": "status 用于展示系统实时健康状态，包括服务可用性、任务队列、错误率和延迟。",
    "boundary": "只看进程在不在，而不看成功率和积压量，会错判“看似正常”的隐性故障。",
    "signal": "运维值班、发布后观测、故障恢复确认都需要 status 做统一入口。",
    "action": "定义红黄绿阈值并持续上报；status 页面至少包含最近 5 分钟错误率和关键依赖状态。",
    "aliases": [
      "status"
    ]
  },
  {
    "id": "openclaw_dashboard",
    "term": "dashboard",
    "category": "OpenClaw / Clawbot",
    "core": "dashboard 把运行指标、执行记录和异常趋势可视化，帮助团队从“救火”转向“预防”。",
    "boundary": "只堆图不定义决策阈值，面板再漂亮也无法指导行动。",
    "signal": "当问题重复出现却难以复盘时，通常是缺乏可用的观测看板。",
    "action": "先做三块：吞吐、成功率、延迟分位；每块配对应处理动作和责任人。",
    "aliases": [
      "dashboard"
    ]
  },
  {
    "id": "openclaw_dm_pairing",
    "term": "DM pairing / allowlist",
    "category": "OpenClaw / Clawbot",
    "core": "DM pairing / allowlist 用于限制机器人可触达对象，防止误触发扩散和权限越界。",
    "boundary": "默认放开全量对话会把测试流量与生产流量混在一起，风险不可控。",
    "signal": "机器人刚上线或能力迭代阶段，必须先在 allowlist 小范围灰度。",
    "action": "先配白名单账号进行验证；确认稳定后逐步放量，并记录每次放量范围。",
    "aliases": [
      "allowlist",
      "pairing"
    ]
  },
  {
    "id": "openclaw_sandbox",
    "term": "Sandboxing",
    "category": "OpenClaw / Clawbot",
    "core": "Sandboxing 的本质是把执行能力限制在可控边界内，降低命令执行和数据访问风险。",
    "boundary": "把沙箱当性能选项而非安全基线，会在异常输入下暴露宿主机。",
    "signal": "涉及文件系统、shell、网络调用的技能上线前，必须评估沙箱策略。",
    "action": "默认最小权限：只读文件、受限网络、资源配额；高权限操作走显式审批。",
    "aliases": [
      "sandbox"
    ]
  },
  {
    "id": "openclaw_risk_boundary",
    "term": "本地 Agent 风险边界",
    "category": "OpenClaw / Clawbot",
    "core": "本地 Agent 风险边界定义“能做什么、不能做什么、失败时怎么兜底”，是可上线前提。",
    "boundary": "只强调效率不定义边界，最终会把单点错误放大成系统事故。",
    "signal": "当 agent 开始接触真实账户、生产数据或外部系统时，边界文档必须先落地。",
    "action": "建立风险分级矩阵：读/写/执行三类权限；每类定义审批、审计和回滚机制。",
    "aliases": [
      "风险",
      "本地 agent"
    ]
  },
  {
    "id": "n8n_schedule_trigger",
    "term": "n8n Schedule Trigger",
    "category": "n8n 工作流",
    "core": "Schedule Trigger 用于按时间计划稳定触发流程，适合日报、巡检、同步等周期任务。",
    "boundary": "把高实时任务也放定时触发会引入感知延迟。",
    "signal": "任务目标是“每小时/每天固定执行”，而非事件即时响应时使用 schedule。",
    "action": "先定义时区和执行窗口，避开峰值；首次上线用低频验证，再提升频率。",
    "aliases": [
      "n8n",
      "schedule"
    ]
  },
  {
    "id": "n8n_http_request",
    "term": "n8n HTTP Request",
    "category": "n8n 工作流",
    "core": "HTTP Request 节点是 n8n 与外部系统互通的基础，承担取数、提交和状态查询。",
    "boundary": "不设置超时和重试会让节点在外部波动时频繁失败。",
    "signal": "流程需要调用第三方 API 时，HTTP 节点通常是核心依赖。",
    "action": "显式配置 method、headers、timeout；失败分支接 Error Workflow 做告警和重试。",
    "aliases": [
      "http request"
    ]
  },
  {
    "id": "n8n_expressions",
    "term": "n8n Expressions",
    "category": "n8n 工作流",
    "core": "Expressions 让节点参数可动态引用上游数据，实现流程内数据编排。",
    "boundary": "表达式过于复杂会让流程难以维护，调试成本很高。",
    "signal": "当参数依赖前序节点输出或运行时间上下文时，应使用 expressions。",
    "action": "关键表达式写在注释字段并做样例输入验证；复杂转换移到 Code 节点。",
    "aliases": [
      "expressions"
    ]
  },
  {
    "id": "n8n_code_node",
    "term": "n8n Code Node",
    "category": "n8n 工作流",
    "core": "Code Node 用于处理标准节点无法表达的逻辑，如复杂映射、聚合和条件分流。",
    "boundary": "把整条业务流程都塞进代码节点会失去低代码可视化优势。",
    "signal": "遇到字段规则复杂、需多步 JS 运算时，Code 节点最灵活。",
    "action": "代码只做转换不做外部副作用；输入输出字段名固定并附一组测试样例。",
    "aliases": [
      "code node"
    ]
  },
  {
    "id": "n8n_error_trigger",
    "term": "n8n Error Workflow",
    "category": "n8n 工作流",
    "core": "Error Workflow 把失败处理独立出来，确保主流程失败时仍能通知、记录和补偿。",
    "boundary": "失败后无统一处理会导致“任务悄悄失败”无人感知。",
    "signal": "流程进入生产后，Error Workflow 是可靠性必选项而非可选项。",
    "action": "配置 Error Trigger 接收失败上下文，发送告警并附执行链接与重试入口。",
    "aliases": [
      "error trigger",
      "error workflow"
    ]
  },
  {
    "id": "n8n_credentials",
    "term": "n8n 凭据管理",
    "category": "n8n 工作流",
    "core": "凭据管理把密钥集中存储并按节点注入，避免明文暴露在流程 JSON。",
    "boundary": "把 token 写在节点参数里，导出流程后极易泄露。",
    "signal": "涉及第三方 API、数据库或邮件服务时，先建 credentials 再接节点。",
    "action": "按环境拆分凭据（dev/staging/prod），限制编辑权限并定期轮换。",
    "aliases": [
      "credentials"
    ]
  },
  {
    "id": "n8n_execution_logs",
    "term": "n8n 执行日志",
    "category": "n8n 工作流",
    "core": "执行日志记录每次运行输入、输出和失败节点，是回放和复盘的核心证据。",
    "boundary": "只看最终结果不保留执行细节，问题复现几乎不可能。",
    "signal": "流程偶发失败或数据异常时，要先回看执行日志再改逻辑。",
    "action": "开启保留策略并设置过期时间；对关键流程导出失败样本用于回归测试。",
    "aliases": [
      "execution",
      "logs"
    ]
  },
  {
    "id": "n8n_webhook",
    "term": "Webhook 触发",
    "category": "n8n 工作流",
    "core": "Webhook 触发让外部系统以事件驱动启动流程，适合工单、消息和回调场景。",
    "boundary": "直接对公网暴露 webhook 而无签名校验会有滥用风险。",
    "signal": "当流程需要“事件来了就立即处理”时，应优先 webhook 而非定时轮询。",
    "action": "配置验证令牌或签名；上线前用模拟请求覆盖正常和异常 payload。",
    "aliases": [
      "webhook"
    ]
  },
  {
    "id": "cron_schedule",
    "term": "cron 定时",
    "category": "部署与运维",
    "core": "cron 定时是最基础的任务调度方式，适合单机稳定周期任务。",
    "boundary": "把复杂依赖任务都交给 cron，会缺少失败重试和可观测能力。",
    "signal": "任务简单、执行环境固定时，cron 是低成本选择。",
    "action": "crontab 命令中显式设置环境变量和日志重定向；执行结果接入告警。",
    "aliases": [
      "cron"
    ]
  },
  {
    "id": "gha_schedule",
    "term": "GitHub Actions schedule",
    "category": "部署与运维",
    "core": "GitHub Actions schedule 适合仓库内自动任务，如巡检、同步和报告生成。",
    "boundary": "把高实时任务放在 schedule 上会受平台调度延迟影响。",
    "signal": "任务和代码强耦合且希望免维护基础设施时，可优先用 GHA schedule。",
    "action": "配置 `on: schedule` 后在日志打印执行时间和版本，便于追踪偏差。",
    "aliases": [
      "github actions",
      "schedule"
    ]
  },
  {
    "id": "env_management",
    "term": ".env 与环境变量",
    "category": "部署与运维",
    "core": "环境变量管理用于隔离不同环境配置，保证同一代码在多环境行为可控。",
    "boundary": "把配置散落在脚本和代码常量里，排错时难以统一定位。",
    "signal": "出现“测试环境正常、生产异常”时，首先核查环境变量差异。",
    "action": "建立 `.env.example` 作为契约；启动时校验必需变量，缺失即失败退出。",
    "aliases": [
      ".env",
      "环境变量"
    ]
  },
  {
    "id": "secret_rotation",
    "term": "密钥轮换",
    "category": "部署与运维",
    "core": "密钥轮换降低长期泄露风险，是安全运维的常规动作。",
    "boundary": "密钥长期不换，一次泄露可能长期未被发现。",
    "signal": "人员变动、供应商变更或检测到异常调用时应立即轮换密钥。",
    "action": "建立轮换日历和自动化脚本；轮换后回归验证关键调用路径。",
    "aliases": [
      "secret rotation"
    ]
  },
  {
    "id": "structured_logging",
    "term": "结构化日志",
    "category": "部署与运维",
    "core": "结构化日志用统一字段记录事件，便于检索、聚合和自动告警。",
    "boundary": "纯文本日志难以做稳定查询和跨服务关联。",
    "signal": "系统规模扩大后，日志分析效率决定故障恢复速度。",
    "action": "统一输出 JSON 日志，包含 trace_id、level、module、event、duration。",
    "aliases": [
      "logging",
      "结构化"
    ]
  },
  {
    "id": "log_level",
    "term": "日志级别",
    "category": "部署与运维",
    "core": "日志级别用于控制信息粒度，平衡排障能力与存储成本。",
    "boundary": "生产长期开 debug 会淹没关键信号并增加成本。",
    "signal": "日志太少定位不了问题，或太多看不到重点时，要重设级别策略。",
    "action": "默认 INFO，异常用 ERROR，临时排障短期开 DEBUG 并设置自动回退。",
    "aliases": [
      "log level"
    ]
  },
  {
    "id": "health_check",
    "term": "健康检查",
    "category": "部署与运维",
    "core": "健康检查用于持续判断服务是否可用，并为流量切换和自动恢复提供依据。",
    "boundary": "只检查进程存活不检查依赖可用，会误判健康状态。",
    "signal": "发布后需要快速确认可用性时，health check 是第一道保障。",
    "action": "实现就绪检查与存活检查分离；检查数据库、缓存、队列等关键依赖。",
    "aliases": [
      "health check"
    ]
  },
  {
    "id": "incident_response",
    "term": "故障响应流程",
    "category": "部署与运维",
    "core": "故障响应流程把“发现-分级-处置-沟通-复盘”标准化，缩短恢复时间。",
    "boundary": "没有流程会导致多人并行乱改，事故影响扩大。",
    "signal": "系统进入值班阶段后，故障响应流程必须先于规模增长。",
    "action": "预设值班角色和升级路径；故障期间固定节奏同步状态，恢复后立即复盘。",
    "aliases": [
      "incident"
    ]
  },
  {
    "id": "runbook",
    "term": "Runbook",
    "category": "部署与运维",
    "core": "Runbook 是可执行操作手册，保证关键任务在压力场景下也能按步骤完成。",
    "boundary": "只靠个人经验处理故障，人员一换就失效。",
    "signal": "高频操作（重启、扩容、回滚）都应沉淀 runbook。",
    "action": "每个 runbook 包含前置条件、步骤、验证、回滚和联系人。",
    "aliases": [
      "runbook"
    ]
  },
  {
    "id": "rollback",
    "term": "回滚策略",
    "category": "部署与运维",
    "core": "回滚策略用于在发布异常时快速恢复服务，核心是“快、稳、可验证”。",
    "boundary": "没有可回滚版本和数据兼容方案，失败发布会被动拖长。",
    "signal": "每次发布前都应确认回滚路径是否可执行。",
    "action": "保留上一个稳定版本并支持一键切换；回滚后自动执行健康检查。",
    "aliases": [
      "rollback"
    ]
  },
  {
    "id": "stage_localization",
    "term": "分段定位",
    "category": "排障与稳定性",
    "core": "分段定位把复杂链路拆成可验证阶段，快速缩小故障范围。",
    "boundary": "一上来全链路盲改，通常会引入新问题并延长恢复时间。",
    "signal": "报错信息不明确或链路较长时，分段定位是最高效策略。",
    "action": "按“入口->处理->存储->输出”逐段打日志，先确认哪一段首次异常。",
    "aliases": [
      "定位",
      "阶段"
    ]
  },
  {
    "id": "minimal_repro",
    "term": "最小复现",
    "category": "排障与稳定性",
    "core": "最小复现是把问题压缩到最小输入和最短路径，让修复从猜测变为实验。",
    "boundary": "拿生产全量数据调试会干扰变量，难以定位根因。",
    "signal": "同事无法复现你的 bug 时，优先产出最小复现脚本。",
    "action": "保留最小输入样本和单文件脚本，写清环境版本与复现步骤。",
    "aliases": [
      "复现",
      "minimal repro"
    ]
  },
  {
    "id": "selector_fallback",
    "term": "选择器备选",
    "category": "排障与稳定性",
    "core": "选择器备选策略用于页面结构变化时保持采集稳定，避免单点失效导致全量中断。",
    "boundary": "只依赖一个脆弱选择器，站点微调即全盘失败。",
    "signal": "网页采集场景中“偶发空数据”常是选择器不稳而非网络问题。",
    "action": "主选择器失败后按备选列表依次尝试，并记录命中率用于后续优化。",
    "aliases": [
      "selector"
    ]
  },
  {
    "id": "network_diagnosis",
    "term": "网络问题诊断",
    "category": "排障与稳定性",
    "core": "网络问题诊断要区分 DNS、连接、TLS、超时和应用层错误，不同层级处理方式完全不同。",
    "boundary": "把所有请求失败都归因于“目标网站挂了”会误导排障方向。",
    "signal": "接口大量超时或连接失败时，先做分层网络诊断再改业务逻辑。",
    "action": "依次检查 `ping/nslookup/curl -v`，记录失败层级并据此决定重试或降级。",
    "aliases": [
      "网络诊断"
    ]
  },
  {
    "id": "notify_diagnosis",
    "term": "推送故障诊断",
    "category": "排障与稳定性",
    "core": "推送故障诊断关注“消息是否产生、是否发送、是否到达、是否可见”四段链路。",
    "boundary": "只看发送接口返回成功，不代表接收端一定收到。",
    "signal": "告警未触达时，要把链路逐段核对，而不是直接重发。",
    "action": "给每条通知打唯一 trace_id；发送端、网关端、接收端三处日志都能按 id 检索。",
    "aliases": [
      "notify",
      "推送失败"
    ]
  },
  {
    "id": "dependency_pin",
    "term": "依赖版本锁定",
    "category": "排障与稳定性",
    "core": "依赖版本锁定用于防止上游变更导致行为漂移，是可复现构建和稳定运行的基础。",
    "boundary": "允许依赖随时间自动升级，故障出现时很难追责到具体版本。",
    "signal": "“昨天还好今天突然挂”且代码未变时，优先排查依赖版本变化。",
    "action": "锁定关键依赖版本并纳入 CI；升级走小步验证和回滚预案。",
    "aliases": [
      "版本锁定",
      "lock"
    ]
  },
  {
    "id": "safe_rerun",
    "term": "安全重跑",
    "category": "排障与稳定性",
    "core": "安全重跑要求任务具备幂等或补偿机制，避免二次执行造成重复写入。",
    "boundary": "失败后直接重跑而无防重策略，常造成脏数据和重复通知。",
    "signal": "批处理任务中断恢复、消息重复消费场景都需要安全重跑设计。",
    "action": "为任务定义幂等键和执行状态机；重跑前先跳过已成功记录。",
    "aliases": [
      "重跑",
      "rerun"
    ]
  },
  {
    "id": "sampling_validation",
    "term": "抽样校验",
    "category": "排障与稳定性",
    "core": "抽样校验通过小成本人工核查保证自动化结果质量，适合数据处理和模型输出验收。",
    "boundary": "完全不抽样会让系统性错误长期潜伏。",
    "signal": "流程新增规则或外部数据源变更后，应提高抽样比例。",
    "action": "按风险分层抽样（高风险高比例），记录错误类型并反哺规则改进。",
    "aliases": [
      "抽样",
      "校验"
    ]
  },
  {
    "id": "slo_thinking",
    "term": "SLO 思维",
    "category": "排障与稳定性",
    "core": "SLO 思维把“系统要多稳定”量化为目标（如可用性、延迟、错误率），避免稳定性讨论空泛。",
    "boundary": "没有目标就无法判断是否达标，也无法合理取舍开发速度与稳定性。",
    "signal": "服务进入长期运行阶段时，需要从“能跑”升级到“可承诺”。",
    "action": "先定义 1-2 个核心 SLO 和误差预算；每周复盘超标时段与改进动作。",
    "aliases": [
      "SLO",
      "稳定性指标"
    ]
  },
  {
    "id": "postmortem",
    "term": "故障复盘（Postmortem）",
    "category": "排障与稳定性",
    "core": "Postmortem 关注系统性改进，不追责个人，目标是防止同类事故再次发生。",
    "boundary": "复盘只写时间线不落改进项，价值会快速归零。",
    "signal": "出现中高优先级事故后，必须在记忆新鲜时完成复盘。",
    "action": "文档固定包含：影响范围、时间线、根因、处置、长期改进、负责人和截止日期。",
    "aliases": [
      "复盘",
      "postmortem"
    ]
  },
  {
    "id": "opening_control",
    "term": "开场控场",
    "category": "面试表达与控场",
    "core": "开场控场通过先给结构再给细节，帮助面试官快速进入你的叙事节奏。",
    "boundary": "开场即铺陈大量细节会打散重点。",
    "signal": "面试前 3 分钟是建立专业印象和沟通效率的关键窗口。",
    "action": "开场先报三点：当前方向、代表项目、可展示结果，再按追问展开。",
    "aliases": [
      "控场",
      "开场"
    ]
  },
  {
    "id": "self_intro_30s",
    "term": "30 秒自我介绍",
    "category": "面试表达与控场",
    "core": "30 秒自我介绍要传递清晰定位和核心优势，不追求信息量而追求命中率。",
    "boundary": "流水账式履历堆叠会让听者抓不到记忆点。",
    "signal": "面试开始时这是你主动塑造人设的最佳机会。",
    "action": "模板：身份定位 + 关键成果 + 与岗位匹配点，控制在 90 字以内。",
    "aliases": [
      "自我介绍"
    ]
  },
  {
    "id": "project_pitch_2m",
    "term": "2 分钟项目讲解",
    "category": "面试表达与控场",
    "core": "2 分钟项目讲解要覆盖背景、方案、结果和复盘，让听者快速判断价值。",
    "boundary": "只讲技术细节不讲业务结果，会被认为缺少产出导向。",
    "signal": "技术面中被要求“介绍一个项目”时，结构化讲解最能拉开差距。",
    "action": "按 STAR 变体讲：场景、任务、动作、结果、反思；每段一句核心信息。",
    "aliases": [
      "项目讲解",
      "闭环法"
    ]
  },
  {
    "id": "unknown_answer",
    "term": "不会问题应答",
    "category": "面试表达与控场",
    "core": "不会问题应答的关键是诚实、拆解和给出可验证的求解路径。",
    "boundary": "硬编答案短期可能蒙混，深挖时会迅速失分。",
    "signal": "遇到陌生领域问题时，态度和方法比“马上答对”更重要。",
    "action": "先承认未知，再给思考框架和验证步骤，最后说明你会如何补齐。",
    "aliases": [
      "不会怎么答"
    ]
  },
  {
    "id": "fact_based_answer",
    "term": "基于事实回答",
    "category": "面试表达与控场",
    "core": "基于事实回答要求每个结论对应证据，减少主观夸大。",
    "boundary": "大量“我觉得”而无数据支撑，会削弱可信度。",
    "signal": "当面试官追问贡献和效果时，事实化表达是核心能力。",
    "action": "每个主张后补一句证据：指标、日志、截图或他人反馈。",
    "aliases": [
      "事实",
      "追问"
    ]
  },
  {
    "id": "downgrade_statement",
    "term": "降级表述（PoC）",
    "category": "面试表达与控场",
    "core": "降级表述（PoC）用于准确标注成熟度，避免把实验性成果包装成生产能力。",
    "boundary": "夸大可用范围会在细节追问中被反噬。",
    "signal": "项目仍在验证阶段时，主动声明边界能提升专业可信度。",
    "action": "明确说“这是 PoC，已验证 A/B，尚未覆盖 C”，并给出下一步计划。",
    "aliases": [
      "PoC",
      "降级表述"
    ]
  },
  {
    "id": "ai_assist_honesty",
    "term": "AI 辅助开发诚实表达",
    "category": "面试表达与控场",
    "core": "AI 辅助开发诚实表达强调“工具提升效率，但关键决策与验收由你负责”。",
    "boundary": "把成果完全归功于 AI 或完全否认使用 AI 都不可信。",
    "signal": "面试官问到 AI 使用方式时，重点在你的工程判断与质量控制。",
    "action": "说明你如何用 AI 生成初稿、如何测试验证、如何修正错误并沉淀模板。",
    "aliases": [
      "AI 辅助",
      "诚实"
    ]
  },
  {
    "id": "business_questions",
    "term": "结尾反问业务痛点",
    "category": "面试表达与控场",
    "core": "结尾反问业务痛点展示你关注真实问题和协作落地，而非只关心技术细节。",
    "boundary": "反问只问福利或流程，错过展示业务思考的机会。",
    "signal": "面试最后“你有什么想问的”是主动加分时刻。",
    "action": "准备 2 个问题：当前最大业务瓶颈、该岗位首月最关键交付。",
    "aliases": [
      "反问",
      "业务痛点"
    ]
  },
  {
    "id": "learn_by_building",
    "term": "以做代学",
    "category": "学习方法与风险控制",
    "core": "以做代学通过真实任务驱动学习路径，能快速建立“概念-代码-结果”的闭环。",
    "boundary": "只看教程不做项目，知识很难转化为可交付能力。",
    "signal": "时间紧、目标明确（如面试冲刺）时，项目驱动学习效率最高。",
    "action": "每周设一个可运行小项目，完成后做复盘：卡点、方案、可复用模板。",
    "aliases": [
      "项目驱动",
      "做中学"
    ]
  },
  {
    "id": "daily_review",
    "term": "每日复盘",
    "category": "学习方法与风险控制",
    "core": "每日复盘把零散实践沉淀为稳定经验，避免重复踩同一类坑。",
    "boundary": "复盘只写流水账不提改进动作，第二天问题依旧。",
    "signal": "连续几天效率下降或错误重复出现时，说明复盘质量不够。",
    "action": "每天收尾 15 分钟记录“今天学到什么、明天改什么、风险点是什么”。",
    "aliases": [
      "复盘",
      "daily"
    ]
  },
  {
    "id": "line_by_line_explain",
    "term": "关键代码逐行可解释",
    "category": "学习方法与风险控制",
    "core": "关键代码逐行可解释意味着你掌握了控制流和边界条件，而不是只会复制粘贴。",
    "boundary": "“能跑但说不清”在技术面深挖时会迅速暴露。",
    "signal": "面试官让你讲一段核心代码时，逐行解释能力决定信任度。",
    "action": "挑核心模块做口述演练：每行回答“做什么、为什么、失败会怎样”。",
    "aliases": [
      "逐行解释",
      "代码理解"
    ]
  },
  {
    "id": "key_commenting",
    "term": "关键点注释",
    "category": "学习方法与风险控制",
    "core": "关键点注释用于解释设计意图和边界假设，帮助后来者快速理解“为什么这样写”。",
    "boundary": "注释重复代码字面含义会制造噪音。",
    "signal": "涉及协议约束、业务规则或非常规实现时，注释不可省。",
    "action": "只在高复杂段落前写注释，内容聚焦输入约束、异常策略和取舍理由。",
    "aliases": [
      "注释",
      "关键点"
    ]
  },
  {
    "id": "timeboxing",
    "term": "时间盒管理",
    "category": "学习方法与风险控制",
    "core": "时间盒管理通过限定任务时长，避免在低价值细节上无限消耗。",
    "boundary": "没有时间上限的调试容易陷入“忙但无产出”。",
    "signal": "当任务经常超时且优先级混乱时，需要引入时间盒。",
    "action": "每项任务设 30-90 分钟窗口；到点必须做“继续/降级/求助”决策。",
    "aliases": [
      "timebox",
      "时间盒"
    ]
  },
  {
    "id": "authentic_scope",
    "term": "能力边界声明",
    "category": "学习方法与风险控制",
    "core": "能力边界声明体现专业度，明确“我会什么、不会什么、如何补位”比盲目承诺更可信。",
    "boundary": "过度包装短期看似加分，实际工作中会快速失信。",
    "signal": "被问到陌生技术栈或高风险承诺时，边界表达尤其重要。",
    "action": "采用三段式回答：当前掌握、已验证经验、落地补齐计划。",
    "aliases": [
      "边界",
      "真实性"
    ]
  },
  {
    "id": "checklist_execution",
    "term": "清单执行",
    "category": "学习方法与风险控制",
    "core": "清单执行把复杂任务拆成可核对步骤，降低遗漏和认知负荷。",
    "boundary": "把清单写成口号而不绑定检查动作，执行时仍会漏项。",
    "signal": "上线、交付、面试准备这类高压场景最需要清单化。",
    "action": "清单项必须可勾选、可验证；每次事故后把新坑补回清单。",
    "aliases": [
      "checklist",
      "清单"
    ]
  },
  {
    "id": "low_risk_candidate",
    "term": "同预算低风险候选人",
    "category": "岗位与目标",
    "core": "低风险候选人意味着上手快、沟通稳、可预期，不会把团队节奏拖入不确定。",
    "boundary": "只强调“我很拼”但缺少流程意识和协作证据，不足以构成低风险画像。",
    "signal": "预算有限、业务紧急时，招聘方会优先选择低风险而非高潜力。",
    "action": "在回答里突出交付节奏、失败处理和协作习惯，降低对方顾虑。",
    "aliases": [
      "低风险",
      "管理成本",
      "稳定交付"
    ]
  },
  {
    "id": "salary_startdate_clarity",
    "term": "薪资与到岗确定性",
    "category": "岗位与目标",
    "core": "薪资与到岗确定性是招聘决策的现实约束，越清晰越有利于推进流程。",
    "boundary": "模糊承诺或频繁变更预期，会让候选人可靠性评分下降。",
    "signal": "到谈薪和 offer 阶段时，技术表现之外的确定性信息同样关键。",
    "action": "提前给出可接受区间和最早到岗日期，并说明影响因素和最终确认时间。",
    "aliases": [
      "到岗",
      "薪资预期",
      "收口"
    ]
  },
  {
    "id": "resume_one_page_result",
    "term": "一页简历结果前置",
    "category": "交付物与证据",
    "core": "一页简历结果前置强调“先看产出，再看过程”，让筛选者快速识别你的业务价值。",
    "boundary": "简历只列技术栈不写结果，读者无法判断贡献强度。",
    "signal": "投递竞争激烈岗位时，结果前置能显著提升首轮通过率。",
    "action": "每段经历用“动作 + 指标 + 业务影响”一句话表达，并附可追溯证据。",
    "aliases": [
      "一页简历",
      "结果前置",
      "30秒筛选"
    ]
  },
  {
    "id": "week1_delivery_plan",
    "term": "首周交付清单",
    "category": "交付物与证据",
    "core": "首周交付清单体现你能否快速进入状态，核心是低风险可见成果而非大而全规划。",
    "boundary": "第一周就规划重构全系统，通常不现实也不被信任。",
    "signal": "面试官问“你入职第一周做什么”时，这是判断执行力的关键问题。",
    "action": "列 3 项可交付：环境接入、监控基线、一个小闭环优化；每项给验收标准。",
    "aliases": [
      "首周计划",
      "D1 D3 D5",
      "交付承诺"
    ]
  },
  {
    "id": "quantified_outcomes",
    "term": "项目结果量化表达",
    "category": "交付物与证据",
    "core": "结果量化把主观“做得不错”转成客观指标，便于比较改进前后价值。",
    "boundary": "没有基线就谈提升比例，数字会失去可信度。",
    "signal": "项目复盘、晋升述职、面试成果陈述都需要量化结果支撑。",
    "action": "至少记录三个指标：效率、稳定性、成本；给出改造前后对比区间和统计口径。",
    "aliases": [
      "量化",
      "指标",
      "效果"
    ]
  },
  {
    "id": "close_with_hire_signal",
    "term": "收口话术：明日可上班",
    "category": "面试表达与控场",
    "core": "收口话术的目标是传递执行意愿和到岗确定性，帮助面试官降低决策阻力。",
    "boundary": "收尾过于强硬或空泛，都可能产生负面观感。",
    "signal": "面试结束前 30 秒是强化信号的关键时间点。",
    "action": "简洁收口：重申匹配点 + 可到岗时间 + 愿意先做小任务验证。",
    "aliases": [
      "收口话术",
      "到岗信号",
      "offer收口"
    ]
  },
  {
    "id": "live_debug_signal",
    "term": "20 分钟现场排障信号",
    "category": "面试表达与控场",
    "core": "20 分钟现场排障信号体现的是问题拆解能力和沟通过程，而非一次性答对。",
    "boundary": "沉默调试不解释思路，会让面试官无法评估你的方法论。",
    "signal": "实操面或现场 coding 环节，排障过程本身就是评分项。",
    "action": "边做边说：先复现、再分段定位、再最小修复，最后补一条防回归测试。",
    "aliases": [
      "现场排障",
      "debug",
      "四步法"
    ]
  },
  {
    "id": "python_decorator_basics",
    "term": "装饰器（Decorator）",
    "category": "Python 测试与工程细节",
    "core": "装饰器用于在不改原函数主体的前提下增加横切能力，如日志、鉴权、重试。",
    "boundary": "装饰器里夹杂业务逻辑会让调用链难以理解。",
    "signal": "同一前后处理逻辑在多个函数重复出现时，装饰器是更稳的抽象方式。",
    "action": "先实现无参装饰器，再扩展带参数版本；保留原函数签名和文档信息。",
    "aliases": [
      "decorator",
      "@decorator",
      "函数包装"
    ]
  },
  {
    "id": "functools_wraps",
    "term": "functools.wraps",
    "category": "Python 测试与工程细节",
    "core": "`functools.wraps` 用于保留被装饰函数的元数据，保证调试、文档和测试工具行为正常。",
    "boundary": "不加 wraps 会让函数名、注释、签名丢失，影响追踪和反射。",
    "signal": "当装饰后的函数在日志里只显示 `wrapper` 时，通常是漏了 wraps。",
    "action": "在 wrapper 上加 `@wraps(func)`；对依赖签名的框架（如 FastAPI）必须强制使用。",
    "aliases": [
      "@wraps",
      "元信息保留",
      "functools"
    ]
  },
  {
    "id": "pytest_mark_parametrize",
    "term": "pytest 参数化（@pytest.mark.parametrize）",
    "category": "Python 测试与工程细节",
    "core": "参数化测试让同一断言逻辑覆盖多组输入，快速提升边界场景覆盖率。",
    "boundary": "把复杂测试都塞进参数表会降低可读性。",
    "signal": "当你发现多条测试只差输入输出样本时，应该收敛为参数化。",
    "action": "使用 `@pytest.mark.parametrize(\"input,expected\", cases)`；失败信息里包含样本标签。",
    "aliases": [
      "parametrize",
      "pytest.mark",
      "数据驱动测试"
    ]
  },
  {
    "id": "pytest_fixture_scope",
    "term": "pytest fixture 与作用域",
    "category": "Python 测试与工程细节",
    "core": "fixture scope 决定测试资源复用粒度，直接影响测试速度和隔离性。",
    "boundary": "作用域设置过大容易引入跨用例污染。",
    "signal": "测试变慢或互相影响时，先检查 fixture 的创建时机和清理策略。",
    "action": "默认 `function` 保隔离；确有性能瓶颈再升到 `module/session`，并补 teardown。",
    "aliases": [
      "fixture",
      "scope",
      "setup teardown"
    ]
  },
  {
    "id": "py_variable_binding",
    "term": "变量与名称绑定",
    "category": "Python 基础与工程",
    "core": "Python 变量保存的是“对象引用”而不是独立值副本，理解绑定关系是排查可变对象 bug 的起点。",
    "boundary": "把赋值理解成“复制一份新对象”会在列表、字典场景下踩共享引用坑。",
    "signal": "当你改了 A 变量却发现 B 也变了，通常是同一对象被多个名字绑定。",
    "action": "用 `id(obj)` 验证是否同对象；需要副本时显式使用 `copy()` 或 `deepcopy()`。",
    "aliases": []
  },
  {
    "id": "py_dynamic_typing",
    "term": "动态类型",
    "category": "Python 基础与工程",
    "core": "动态类型意味着类型检查发生在运行期，开发速度快，但错误暴露更依赖测试覆盖。",
    "boundary": "把“动态”理解成“可以随意混类型”会让函数契约变得不可预测。",
    "signal": "函数在某些输入正常、某些输入崩溃时，往往是类型约束没有写清。",
    "action": "关键函数加类型注解并在入口做 `isinstance` 校验；配合 mypy/pytest 兜底。",
    "aliases": []
  },
  {
    "id": "py_type_hints",
    "term": "类型提示 Type Hints",
    "category": "Python 基础与工程",
    "core": "类型提示提升可读性和可维护性，让 IDE 与静态检查工具提前发现不匹配调用。",
    "boundary": "注解写了却从不校验，等于把文档当装饰品。",
    "signal": "代码规模扩大、多人协作或函数参数复杂时，type hints 会明显降低沟通成本。",
    "action": "从公共接口开始补注解，CI 加 `mypy` 检查；对复杂返回值优先用 `TypedDict` 或 dataclass。",
    "aliases": []
  },
  {
    "id": "py_int_float_str",
    "term": "int/float/str 基本类型",
    "category": "Python 基础与工程",
    "core": "`int/float/str` 的差异不只在存储类型，还影响比较、序列化和精度行为。",
    "boundary": "把金额等精确数值用 float 处理，容易出现累计误差。",
    "signal": "涉及用户输入解析、金额计算、接口序列化时，基础类型选择会直接影响正确性。",
    "action": "外部输入先做显式转换和异常捕获；金额优先 `Decimal`，展示层再转字符串。",
    "aliases": []
  },
  {
    "id": "py_bool_truthy",
    "term": "Truthy/Falsy",
    "category": "Python 基础与工程",
    "core": "Truthy/Falsy 规则决定对象在条件判断中的行为，能写出简洁代码，也容易引发隐式判断误解。",
    "boundary": "把“空字符串、0、None”混为同一语义，会让业务分支错误触发。",
    "signal": "条件判断看似正确但出现漏判时，先确认对象的布尔语义。",
    "action": "对关键分支用显式判断：`is None`、`== 0`、`len(x)==0`，避免过度依赖隐式 truthy。",
    "aliases": []
  },
  {
    "id": "py_list_basics",
    "term": "列表 List 基础",
    "category": "Python 基础与工程",
    "core": "List 是有序可变序列，适合频繁追加和按位置访问，但中间插入删除成本较高。",
    "boundary": "把 list 当集合去重会造成性能和语义双重问题。",
    "signal": "数据规模增长后出现处理变慢，需要回看列表操作模式是否匹配。",
    "action": "追加用 `append/extend`，查重或成员判断频繁时改用 `set` 或 `dict`。",
    "aliases": []
  },
  {
    "id": "py_dict_basics",
    "term": "字典 Dict 基础",
    "category": "Python 基础与工程",
    "core": "Dict 通过键快速定位值，适合配置、索引和聚合场景，是 Python 最常用的数据骨架。",
    "boundary": "直接索引不存在键会抛 `KeyError`，线上常见于脏数据输入。",
    "signal": "解析 API 响应或按 id 聚合数据时，dict 往往是第一选择。",
    "action": "读取用 `get` 提供默认值；嵌套字典先判空再取值，必要时封装安全读取函数。",
    "aliases": []
  },
  {
    "id": "py_tuple_set",
    "term": "元组与集合",
    "category": "Python 基础与工程",
    "core": "Tuple 强调不可变结构，Set 强调无序去重，两者都用于表达“边界明确”的数据语义。",
    "boundary": "依赖 set 的顺序会得到不稳定结果，测试容易偶发失败。",
    "signal": "需要唯一值集合或作为字典键的不可变结构时，应在 tuple/set 间明确选择。",
    "action": "去重用 `set(data)`，需要稳定顺序就先排序；固定记录结构用 tuple 或 dataclass。",
    "aliases": []
  },
  {
    "id": "py_list_comprehension",
    "term": "列表推导式",
    "category": "Python 基础与工程",
    "core": "列表推导式适合中小规模数据转换，把“遍历+过滤+映射”压缩为可读表达式。",
    "boundary": "在推导式里塞多层复杂逻辑会牺牲可维护性。",
    "signal": "当你写出 4 行以内的简单循环转换时，推导式通常更清晰。",
    "action": "规则是“单层循环 + 可读条件”；超过这个复杂度就改回普通 for 循环并加注释。",
    "aliases": []
  },
  {
    "id": "py_dict_comprehension",
    "term": "字典推导式",
    "category": "Python 基础与工程",
    "core": "字典推导式用于快速构建索引映射，常见于字段投影、反查表和统计结果组装。",
    "boundary": "键冲突时后值覆盖前值，若无意识会造成数据静默丢失。",
    "signal": "从列表生成 id->对象 的索引结构时，dict 推导式效率和可读性都很高。",
    "action": "先确认键唯一性；不唯一场景改用 `defaultdict(list)` 做聚合。",
    "aliases": []
  },
  {
    "id": "py_generator_yield",
    "term": "生成器与 yield",
    "category": "Python 基础与工程",
    "core": "生成器通过惰性计算按需产出数据，能把大数据处理从“吃内存”改为“走流式”。",
    "boundary": "把一次性可迭代对象重复消费会得到空结果，这是生成器常见陷阱。",
    "signal": "处理日志、文件或分页接口时，数据量大到不适合一次全载入时应优先考虑 generator。",
    "action": "函数中使用 `yield` 逐条返回；必要时用 `itertools.tee` 或先 `list()` 固化避免二次消费问题。",
    "aliases": []
  },
  {
    "id": "py_if_elif_else",
    "term": "if/elif/else 条件语句",
    "category": "Python 基础与工程",
    "core": "条件分支的关键不是语法，而是把业务规则写成互斥且可读的判定顺序。",
    "boundary": "分支条件重叠会让结果依赖代码顺序，后续维护非常脆弱。",
    "signal": "规则越来越多时，if 链会迅速膨胀，需要重构成映射表或策略模式。",
    "action": "先写“最特殊到最一般”的顺序；每个分支补单测，防止新增规则破坏既有逻辑。",
    "aliases": []
  },
  {
    "id": "py_for_loop",
    "term": "for 循环与可迭代对象",
    "category": "Python 基础与工程",
    "core": "for 循环基于迭代协议，天然适合遍历集合并逐步累计结果。",
    "boundary": "手动管理索引容易越界或漏元素，除非确有必要不必写 C 风格循环。",
    "signal": "需要按元素处理、统计或转换数据时，for 循环最直观。",
    "action": "优先用 `for item in data`；需要索引时用 `enumerate(data)`，避免手写计数器。",
    "aliases": []
  },
  {
    "id": "py_while_loop",
    "term": "while 循环与哨兵模式",
    "category": "Python 基础与工程",
    "core": "while 适合“条件驱动直到满足退出”的场景，如重试、轮询和状态机推进。",
    "boundary": "忘记更新退出条件会造成死循环，生产环境风险很高。",
    "signal": "当循环次数不可预知且由外部状态决定时，while 比 for 更贴切。",
    "action": "设置明确哨兵条件和最大迭代次数；重试循环里记录当前次数和最后错误。",
    "aliases": []
  },
  {
    "id": "py_function_def",
    "term": "函数定义与调用",
    "category": "Python 基础与工程",
    "core": "函数定义的价值是抽象重复逻辑并明确输入输出契约，不只是“把代码包起来”。",
    "boundary": "函数职责过多会导致测试困难和复用失败。",
    "signal": "同一段逻辑出现两次以上时，就应考虑提取函数。",
    "action": "函数名写业务动词，参数控制在可读范围内；返回值结构固定并写 docstring。",
    "aliases": []
  },
  {
    "id": "py_args_kwargs",
    "term": "*args 与 **kwargs",
    "category": "Python 基础与工程",
    "core": "`*args/**kwargs` 让函数支持可变参数，适合封装中间层透传和扩展接口。",
    "boundary": "滥用可变参数会掩盖真实接口契约，调用方难以发现拼写错误。",
    "signal": "你在写装饰器、代理函数或 SDK 封装时，经常需要透传未知参数。",
    "action": "对外公开函数尽量显式参数；仅在桥接层使用 `*args/**kwargs` 并补参数校验。",
    "aliases": []
  },
  {
    "id": "py_lambda",
    "term": "lambda 匿名函数",
    "category": "Python 基础与工程",
    "core": "lambda 适合短小、一次性的函数表达，常用于排序键和简单映射。",
    "boundary": "把复杂逻辑塞进 lambda 会降低可读性，也不便调试。",
    "signal": "当函数只用一次且逻辑一眼可读时，lambda 能减少样板代码。",
    "action": "限定为单表达式；超过一行语义时改成 `def` 并命名。",
    "aliases": []
  },
  {
    "id": "py_scope_legb",
    "term": "LEGB 作用域",
    "category": "Python 基础与工程",
    "core": "LEGB 规则定义变量解析顺序（Local/Enclosing/Global/Builtins），决定你读到的到底是哪个名字。",
    "boundary": "在函数里误改全局变量会制造隐蔽副作用。",
    "signal": "遇到“变量值和预期不一致”时，先按 LEGB 路径定位名称来源。",
    "action": "避免同名遮蔽；需要修改外层变量时显式使用 `nonlocal` 或 `global` 并写注释。",
    "aliases": []
  },
  {
    "id": "py_exception_try",
    "term": "异常处理 try/except/finally",
    "category": "Python 基础与工程",
    "core": "异常处理把“非正常路径”显式化，关键在于分类处理和资源收尾，而不是吞掉错误。",
    "boundary": "裸 `except` 会掩盖真实问题，导致故障长期潜伏。",
    "signal": "涉及 IO、网络、外部依赖的代码必须先设计异常路径。",
    "action": "只捕获明确异常类型；在 `finally` 做清理，并在日志中记录上下文参数。",
    "aliases": []
  },
  {
    "id": "py_raise_custom",
    "term": "自定义异常与 raise",
    "category": "Python 基础与工程",
    "core": "自定义异常用于表达业务语义错误，让调用方能按错误类型做差异化处理。",
    "boundary": "到处抛 `Exception` 会让上层无法判断是参数错、状态错还是系统错。",
    "signal": "当业务规则复杂且需要明确失败原因时，应定义领域异常。",
    "action": "定义 `class BizError(Exception)`；异常信息包含关键字段，调用层按类型捕获并映射返回码。",
    "aliases": []
  },
  {
    "id": "py_with_context",
    "term": "with 上下文管理器",
    "category": "Python 基础与工程",
    "core": "with 上下文管理器把资源获取和释放绑定到作用域，避免异常分支遗漏清理。",
    "boundary": "手动 open/close 一旦中途抛错，资源可能泄漏。",
    "signal": "文件、数据库连接、锁、临时目录等需要成对管理资源时，优先使用 with。",
    "action": "对支持上下文协议的对象统一改为 `with ... as ...`；自定义资源实现 `__enter__/__exit__`。",
    "aliases": []
  },
  {
    "id": "py_file_io",
    "term": "文件读写 open/read/write",
    "category": "Python 基础与工程",
    "core": "文件读写要同时考虑编码、模式和错误处理，才能保证跨平台和大文件场景稳定。",
    "boundary": "省略编码参数在不同系统上可能出现乱码或解码失败。",
    "signal": "处理日志、配置或导入导出文件时，I/O 细节会直接决定结果正确性。",
    "action": "文本文件统一 `encoding=\"utf-8\"`；大文件用分块读取，写入后立即 flush/close。",
    "aliases": []
  },
  {
    "id": "py_pathlib",
    "term": "pathlib 路径操作",
    "category": "Python 基础与工程",
    "core": "pathlib 以对象方式操作路径，提升跨平台兼容性和代码可读性。",
    "boundary": "手拼路径分隔符在不同操作系统上易出错。",
    "signal": "项目涉及大量文件路径拼接、遍历、存在性判断时，pathlib 比 `os.path` 更直观。",
    "action": "用 `Path` 处理路径、`glob` 搜索文件、`mkdir(parents=True, exist_ok=True)` 创建目录。",
    "aliases": []
  },
  {
    "id": "py_module_import",
    "term": "模块与 import 机制",
    "category": "Python 基础与工程",
    "core": "import 机制决定命名空间和依赖加载顺序，合理模块化是工程代码可扩展的前提。",
    "boundary": "循环导入通常来自边界不清，后期会引发启动错误和隐式副作用。",
    "signal": "项目从脚本增长为包结构时，必须重构模块边界和导入路径。",
    "action": "公共类型放独立模块；入口文件避免反向依赖业务层，必要时用延迟导入解循环。",
    "aliases": []
  },
  {
    "id": "py_virtualenv",
    "term": "虚拟环境 venv",
    "category": "Python 基础与工程",
    "core": "虚拟环境用于隔离项目依赖，避免不同项目互相污染 Python 包版本。",
    "boundary": "直接使用系统 Python 安装包，常导致“在我机器能跑”问题。",
    "signal": "同机多项目开发或线上问题复现时，虚拟环境是基本盘。",
    "action": "执行 `python3 -m venv .venv` 并激活；把解释器路径固定到项目级配置。",
    "aliases": []
  },
  {
    "id": "py_pip_requirements",
    "term": "pip 与 requirements.txt",
    "category": "Python 基础与工程",
    "core": "requirements.txt 固化依赖版本，让团队和 CI 安装结果可复现。",
    "boundary": "只写无版本依赖会导致时间推移后环境漂移。",
    "signal": "部署失败、测试偶发失败且与依赖升级相关时，要先审查依赖锁定策略。",
    "action": "开发稳定后执行 `pip freeze > requirements.txt`；变更依赖时同步更新并在 CI 复验。",
    "aliases": []
  },
  {
    "id": "py_class_basics",
    "term": "类与实例基础",
    "category": "Python 基础与工程",
    "core": "类把状态与行为封装在一起，适合表达有生命周期和不变量的业务对象。",
    "boundary": "为简单数据流程强行上类会增加样板代码。",
    "signal": "当多个函数反复传递同一组字段且存在方法语义时，类模型更合适。",
    "action": "先定义最小字段和核心方法；把校验放在 `__init__` 或工厂方法里。",
    "aliases": []
  },
  {
    "id": "py_dunder_methods",
    "term": "魔术方法 __init__/__str__/__repr__",
    "category": "Python 基础与工程",
    "core": "魔术方法定义对象在语言协议中的行为，如构造、打印、比较、迭代。",
    "boundary": "只实现 `__str__` 不实现 `__repr__`，调试日志可读性会下降。",
    "signal": "对象需要在日志、交互式调试或容器操作中表现一致时，要补齐关键 dunder。",
    "action": "至少实现 `__repr__` 用于调试；涉及排序或哈希时再实现 `__eq__`、`__hash__`。",
    "aliases": []
  },
  {
    "id": "py_dataclass",
    "term": "dataclass 数据类",
    "category": "Python 基础与工程",
    "core": "dataclass 适合“以数据为中心”的对象，自动生成构造和比较逻辑，减少模板代码。",
    "boundary": "可变默认值处理不当会造成实例间共享状态。",
    "signal": "当类主要用于承载字段而非复杂行为时，dataclass 能提升开发效率。",
    "action": "使用 `field(default_factory=list)` 处理可变字段；必要时设置 `frozen=True` 强化不可变性。",
    "aliases": []
  },
  {
    "id": "py_string_methods",
    "term": "字符串常用方法",
    "category": "Python 基础与工程",
    "core": "字符串方法是文本清洗基础设施，直接影响日志解析、输入校验和数据标准化质量。",
    "boundary": "链式调用过多且无中间变量，会让调试定位困难。",
    "signal": "处理用户输入、文件内容或网页文本时，字符串规范化是第一步。",
    "action": "常用顺序：`strip -> normalize case -> replace -> split/join`，每步保留单测样例。",
    "aliases": []
  },
  {
    "id": "py_regex_basics",
    "term": "正则表达式基础 re",
    "category": "Python 基础与工程",
    "core": "正则用于模式匹配和提取，擅长半结构化文本处理，但需要控制复杂度。",
    "boundary": "用一个超长正则解决所有问题，后期几乎不可维护。",
    "signal": "当字符串规则稳定且重复出现时，可用正则替代手写切片逻辑。",
    "action": "从最小可读模式开始，使用命名分组并配 `re.compile`；关键模式附测试样例。",
    "aliases": []
  },
  {
    "id": "http_request_response",
    "term": "HTTP 请求-响应模型",
    "category": "HTTP / 网络基础",
    "core": "HTTP 请求-响应模型定义了客户端与服务端的标准交互：请求携带意图，响应返回结果与状态。",
    "boundary": "把一次 HTTP 调用当“黑盒成功/失败”会漏掉状态码、头部、超时等关键诊断信号。",
    "signal": "接口对接初期、联调失败或线上 API 异常时，先回到请求-响应基本面排查。",
    "action": "用 `curl -i <url>` 同时看状态行、响应头和响应体；记录请求参数以便复现。",
    "aliases": []
  },
  {
    "id": "http_get_post",
    "term": "GET 与 POST 方法",
    "category": "HTTP / 网络基础",
    "core": "GET 通常用于读取资源，POST 用于提交数据或触发处理，语义差异影响缓存、幂等和安全策略。",
    "boundary": "把“所有操作都用 POST”会增加排障成本，也破坏接口可读性。",
    "signal": "设计新接口或评审第三方 API 时，方法语义是否匹配是第一检查点。",
    "action": "读取接口优先 GET，写入接口用 POST/PUT/PATCH；在文档里写明幂等性和重试策略。",
    "aliases": []
  },
  {
    "id": "http_status_codes",
    "term": "状态码分类 2xx/3xx/4xx/5xx",
    "category": "HTTP / 网络基础",
    "core": "状态码是接口健康信号：2xx 成功，4xx 客户端问题，5xx 服务端故障，3xx 重定向流程。",
    "boundary": "只看响应体文字忽略状态码，会把权限问题误判成业务逻辑错误。",
    "signal": "接口调用失败时，优先按状态码分流处理路径，而不是先改业务代码。",
    "action": "先分三层处理：`>=500` 重试并告警、`4xx` 校验请求、`2xx` 再解析业务字段。",
    "aliases": []
  },
  {
    "id": "http_headers",
    "term": "请求头与响应头",
    "category": "HTTP / 网络基础",
    "core": "请求头和响应头承载协议元信息，如鉴权、缓存、内容协商和追踪标识。",
    "boundary": "忽略 headers 会导致“看起来参数对了却仍失败”的隐性问题。",
    "signal": "遇到 401、跨域、缓存错乱或编码异常时，几乎都要检查头部。",
    "action": "联调时固定打印 `Authorization/Content-Type/Accept/Set-Cookie` 等关键头。",
    "aliases": []
  },
  {
    "id": "http_content_type",
    "term": "Content-Type 与数据格式",
    "category": "HTTP / 网络基础",
    "core": "Content-Type 决定消息体解析方式，是客户端与服务端达成格式契约的关键。",
    "boundary": "请求体是 JSON 却不设 `application/json`，服务端可能按表单解析导致字段全空。",
    "signal": "接口返回 400 且提示参数缺失时，先确认 Content-Type 与 body 编码是否匹配。",
    "action": "JSON 请求统一设置 `Content-Type: application/json`，并校验 body 是否为合法 JSON 字符串。",
    "aliases": []
  },
  {
    "id": "http_json_body",
    "term": "JSON 请求体与响应体",
    "category": "HTTP / 网络基础",
    "core": "JSON body 用结构化键值传输业务数据，便于跨语言互通和字段扩展。",
    "boundary": "把 JSON 当自由文本拼接，容易引入转义错误和字段类型漂移。",
    "signal": "当接口需要嵌套对象、数组或可选字段时，应优先采用 JSON body。",
    "action": "请求前做 schema 校验；响应后先判空再按字段读取，避免直接链式索引崩溃。",
    "aliases": []
  },
  {
    "id": "http_query_params",
    "term": "URL 查询参数",
    "category": "HTTP / 网络基础",
    "core": "查询参数适合表达筛选、排序、分页等“读取条件”，能让 URL 具备可分享和可复现性。",
    "boundary": "把敏感信息放到 query 会被日志和浏览器历史长期暴露。",
    "signal": "当你需要复现某次查询结果时，完整 URL 往往就是最小复现场景。",
    "action": "分页统一使用 `page/size` 或 `offset/limit`；参数编码用库函数生成，避免手拼 URL。",
    "aliases": []
  },
  {
    "id": "http_cookie_session",
    "term": "Cookie 与 Session",
    "category": "HTTP / 网络基础",
    "core": "Cookie 在客户端保存会话标识，Session 在服务端保存状态，两者协同实现登录态延续。",
    "boundary": "把敏感数据直接放 Cookie 而不签名/加密，会带来篡改和泄露风险。",
    "signal": "遇到“接口在浏览器已登录但脚本请求未登录”时，通常是 Cookie/Session 传递链路断了。",
    "action": "先抓包确认 `Set-Cookie` 与后续请求 Cookie；跨域场景检查 SameSite 和凭据策略。",
    "aliases": []
  },
  {
    "id": "http_auth_bearer",
    "term": "Bearer Token 鉴权",
    "category": "HTTP / 网络基础",
    "core": "Bearer Token 鉴权通过 `Authorization` 头传令牌，服务端据此识别调用方身份和权限。",
    "boundary": "把 token 写死在代码或日志中，常导致凭据泄露与权限滥用。",
    "signal": "返回 401/403 时，应先验证 token 是否过期、范围是否匹配、头格式是否正确。",
    "action": "请求头使用 `Authorization: Bearer <token>`；令牌放环境变量并设置轮换周期。",
    "aliases": []
  },
  {
    "id": "http_rest_convention",
    "term": "RESTful API 约定",
    "category": "HTTP / 网络基础",
    "core": "REST 约定强调“资源 + 方法 + 状态码”的一致表达，让接口直观可预测。",
    "boundary": "URL 用动词堆砌且状态码乱用，会让客户端无法可靠处理失败场景。",
    "signal": "设计新服务或重构老接口时，REST 一致性能显著降低协作摩擦。",
    "action": "资源用名词复数路径，动作靠 HTTP 方法表达；错误返回统一结构（code/message/detail）。",
    "aliases": []
  },
  {
    "id": "http_api_versioning",
    "term": "API 版本管理",
    "category": "HTTP / 网络基础",
    "core": "API 版本管理用于在演进接口时兼顾新增能力和旧客户端兼容。",
    "boundary": "直接“无版本破坏式修改”会让存量调用方瞬间失效。",
    "signal": "当字段语义变更或响应结构重构不可避免时，应先定义版本策略。",
    "action": "采用路径或 header 版本号（如 `/v1`）；发布前提供迁移说明和双版本并行窗口。",
    "aliases": []
  },
  {
    "id": "http_cors_basics",
    "term": "CORS 跨域基础",
    "category": "HTTP / 网络基础",
    "core": "CORS 是浏览器侧跨域访问控制机制，决定前端能否读取目标域响应。",
    "boundary": "把 CORS 当服务端“开放所有来源”开关，会引入安全面暴露。",
    "signal": "接口在 Postman 正常但浏览器报跨域，基本就是 CORS 配置问题。",
    "action": "最小化允许域名和方法，必要时只对特定路由放开；调试时同时看预检 OPTIONS 请求。",
    "aliases": []
  },
  {
    "id": "http_ssl_tls",
    "term": "HTTPS 与 TLS 基础",
    "category": "HTTP / 网络基础",
    "core": "HTTPS 通过 TLS 提供传输加密、身份验证和数据完整性校验，是生产系统默认基线。",
    "boundary": "把证书问题视为“偶发网络波动”会掩盖中间人风险和配置缺陷。",
    "signal": "出现证书过期、握手失败或 mixed content 报错时，要从 TLS 链路层排查。",
    "action": "定期检查证书有效期和链路配置；生产环境强制 HTTPS 并开启 HSTS。",
    "aliases": []
  },
  {
    "id": "http_devtools",
    "term": "DevTools 网络面板",
    "category": "HTTP / 网络基础",
    "core": "DevTools Network 面板能按时间线还原请求全过程，是前端接口排障效率最高的入口。",
    "boundary": "只看页面报错弹窗，不看请求详情，会错过关键头部、重定向和缓存信息。",
    "signal": "页面“看起来没反应”或数据异常时，第一步应抓到失败请求条目。",
    "action": "按请求名过滤，重点看 Status、Timing、Response、Initiator，并导出 HAR 供后续复盘。",
    "aliases": []
  },
  {
    "id": "http_curl_basics",
    "term": "curl 命令基础",
    "category": "HTTP / 网络基础",
    "core": "curl 能把页面行为还原成纯协议调用，是接口联调、复现和自动化脚本化的基础工具。",
    "boundary": "只在浏览器里点点点，不沉淀 curl 命令，会让复现过程不可分享。",
    "signal": "当你需要向后端证明“同参数仍失败”，curl 是最具说服力的证据格式。",
    "action": "先用 `curl -i` 验证响应，再补 `-H`、`-d`、`--max-time`；最终把命令存进 runbook。",
    "aliases": []
  },
  {
    "id": "git_init_clone",
    "term": "git init / clone",
    "category": "Git 与版本控制",
    "core": "`git init` 建立本地版本库，`git clone` 获取远程历史；它们决定项目历史从哪里开始接轨。",
    "boundary": "把现有项目直接复制目录继续开发而不保留提交历史，会丢失可追溯性。",
    "signal": "新项目启动或接手老项目时，第一步就是确认仓库来源和默认分支。",
    "action": "新建仓库用 `git init`；已有远端用 `git clone <url>`，随后立即执行 `git remote -v` 核对地址。",
    "aliases": []
  },
  {
    "id": "git_add_commit",
    "term": "git add / commit",
    "category": "Git 与版本控制",
    "core": "`add` 是选择本次提交内容，`commit` 是写入历史快照；两步分离能精确表达一次变更意图。",
    "boundary": "直接 `git add .` 再提交容易把无关改动打包，后续回滚和 review 都会变难。",
    "signal": "当 PR 体积失控或 reviewer 看不懂改动范围时，多半是暂存策略有问题。",
    "action": "先 `git status` 看改动，再按文件 `git add <file>`；提交信息写“动词+对象+原因”。",
    "aliases": []
  },
  {
    "id": "git_status_diff",
    "term": "git status / diff",
    "category": "Git 与版本控制",
    "core": "`status` 告诉你仓库状态，`diff` 告诉你具体变化；这是提交前自检的最小闭环。",
    "boundary": "不看 diff 就提交，常见后果是调试代码、临时日志或密钥误入历史。",
    "signal": "每次 commit 前、每次 rebase 后，都需要用 status/diff 做一次确认。",
    "action": "执行 `git status`、`git diff`、`git diff --staged` 三连检查，确认后再 commit。",
    "aliases": []
  },
  {
    "id": "git_log_history",
    "term": "git log 查看历史",
    "category": "Git 与版本控制",
    "core": "`git log` 用于按时间线追踪“谁在什么时候改了什么以及为什么改”，是排障和回溯关键证据。",
    "boundary": "提交信息随意（如 update/fix）会让 log 失去诊断价值。",
    "signal": "线上回归后需要定位可疑提交、或者准备变更复盘时，log 是第一入口。",
    "action": "使用 `git log --oneline --decorate --graph -20` 快速查看主线，再配合 `git show <sha>` 精读单提交。",
    "aliases": []
  },
  {
    "id": "git_push_pull",
    "term": "git push / pull",
    "category": "Git 与版本控制",
    "core": "`pull` 同步远端变化，`push` 发布本地提交；节奏正确可以减少冲突和返工。",
    "boundary": "长时间不 pull 会累积大冲突；频繁强推会破坏团队协作稳定性。",
    "signal": "开始一天开发前、发起 PR 前都应先同步主分支状态。",
    "action": "执行 `git pull --rebase origin main` 同步后再 `git push origin <branch>`，确保历史线性。",
    "aliases": []
  },
  {
    "id": "git_branch_basics",
    "term": "分支创建与切换",
    "category": "Git 与版本控制",
    "core": "分支是并行开发隔离机制，让新功能、修复和实验互不干扰。",
    "boundary": "多人直接在 main 开发会把高风险改动直接暴露给所有人。",
    "signal": "任何超过 1 小时的开发任务都应在独立分支完成。",
    "action": "从主分支拉新分支：`git switch main && git pull && git switch -c feat/<topic>`。",
    "aliases": []
  },
  {
    "id": "git_merge",
    "term": "合并与冲突解决",
    "category": "Git 与版本控制",
    "core": "merge 把两条历史汇合，冲突解决本质上是在代码层做决策并留下可审计记录。",
    "boundary": "机械接受 ours/theirs 可能“看起来过了”但悄悄丢掉逻辑。",
    "signal": "分支长期未同步、多人改同一模块时，冲突概率显著上升。",
    "action": "先在本地 merge 并跑测试；冲突文件逐段比对后再 `git add` + `git commit` 完成合并。",
    "aliases": []
  },
  {
    "id": "git_pull_request",
    "term": "Pull Request 流程",
    "category": "Git 与版本控制",
    "core": "PR 是协作质量门，目标不是走流程，而是让变更意图、风险和验证证据可被他人快速理解。",
    "boundary": "只贴“大量代码”不写背景和验证步骤，会把 review 成本转嫁给同事。",
    "signal": "任何进入主分支的非紧急改动，都应经过 PR 和至少一次有效评审。",
    "action": "PR 描述固定四段：背景、改动点、验证方式、回滚方案；附关键截图或日志。",
    "aliases": []
  },
  {
    "id": "git_gitignore",
    "term": ".gitignore 配置",
    "category": "Git 与版本控制",
    "core": "`.gitignore` 用于定义“哪些文件不应进入版本历史”，保护仓库整洁和信息安全。",
    "boundary": "把已提交的敏感文件写进 ignore 并不会自动从历史移除。",
    "signal": "项目引入构建产物、临时缓存或本地配置时，应立即更新 ignore 规则。",
    "action": "先更新 `.gitignore`，再用 `git rm --cached <file>` 清理已追踪文件，最后提交规则变更。",
    "aliases": []
  },
  {
    "id": "git_reset_revert",
    "term": "撤销操作 reset / revert",
    "category": "Git 与版本控制",
    "core": "`reset` 适合本地历史整理，`revert` 适合公共历史回滚；选择错误会影响协作安全。",
    "boundary": "在共享分支用 reset 改写历史，会让他人分支出现难解冲突。",
    "signal": "当你需要“撤销一个已发布错误提交”时，优先考虑 revert。",
    "action": "本地未推送改动可 `git reset --soft HEAD~1`；已推送改动使用 `git revert <sha>`。",
    "aliases": []
  },
  {
    "id": "git_stash",
    "term": "git stash 暂存",
    "category": "Git 与版本控制",
    "core": "stash 用于临时封存未完成改动，方便中断当前任务切换到紧急修复。",
    "boundary": "长期把重要改动放在 stash 容易遗忘，最终形成“隐形分支”。",
    "signal": "当你还没准备好提交，却必须立刻切换分支处理新任务时。",
    "action": "`git stash push -m \"wip:<topic>\"` 保存现场；处理完后 `git stash list` + `git stash pop` 恢复。",
    "aliases": []
  },
  {
    "id": "git_remote",
    "term": "远程仓库管理",
    "category": "Git 与版本控制",
    "core": "remote 定义仓库协作边界（origin/upstream），是同步、提交流向和权限控制的基础。",
    "boundary": "远端地址配错会导致代码推到错误仓库，带来泄露或流程事故。",
    "signal": "fork 协作、多远端同步或迁移平台时，必须先梳理 remote 拓扑。",
    "action": "用 `git remote -v` 审核读写地址；需要修正时执行 `git remote set-url origin <url>`。",
    "aliases": []
  },
  {
    "id": "git_commit_message",
    "term": "提交信息规范",
    "category": "Git 与版本控制",
    "core": "提交信息是未来排障和审计的索引，写清“做了什么 + 为什么做”能显著降低认知成本。",
    "boundary": "“update”“fix bug”这类空洞信息在回溯阶段几乎没有价值。",
    "signal": "当团队开始做 changelog、自动发布或规范化 review 时，message 质量会直接影响效率。",
    "action": "采用 `type(scope): summary`，正文补充风险和验证方式，例如 `fix(parser): handle empty payload`。",
    "aliases": []
  },
  {
    "id": "git_tag_release",
    "term": "标签与版本发布",
    "category": "Git 与版本控制",
    "core": "tag 是发布快照锚点，用于把代码状态与可交付版本绑定。",
    "boundary": "直接用分支名代表版本会让回滚和审计缺乏确定性。",
    "signal": "每次对外发布、给测试或运营交付可安装包时，都应打明确标签。",
    "action": "`git tag -a v1.2.0 -m \"release v1.2.0\"` 后 `git push origin v1.2.0`，并在发布说明中引用 tag。",
    "aliases": []
  },
  {
    "id": "git_workflow_model",
    "term": "Feature Branch 工作流",
    "category": "Git 与版本控制",
    "core": "Feature Branch 工作流把“开发、评审、合并”拆成稳定流程，目标是让主分支始终可发布。",
    "boundary": "分支生命周期过长会导致集成冲突和上下文丢失。",
    "signal": "当团队人数增长、需求并行推进时，必须用统一工作流控制节奏。",
    "action": "小步提交、短分支周期；每天 rebase 主分支一次，完成后通过 PR 合并并及时删除分支。",
    "aliases": []
  },
  {
    "id": "ci_what_why",
    "term": "CI 的目的与价值",
    "category": "CI/CD 与 GitHub Actions",
    "core": "CI 的价值不是“跑个脚本”，而是把每次提交都变成可验证的质量检查点，尽早拦截回归缺陷。",
    "boundary": "很多团队把 CI 只当测试触发器，忽略构建、静态检查和制品管理，最终问题仍在上线后暴露。",
    "signal": "当你发现“本地能跑、线上挂掉”反复出现，或者 PR 合并后经常炸主干时，需要先补 CI 基线。",
    "action": "在 `.github/workflows/ci.yml` 里先落三步：安装依赖、运行测试、上传日志；确保 PR 必须通过后才能合并。",
    "aliases": []
  },
  {
    "id": "ci_workflow_yaml",
    "term": "workflow YAML 结构",
    "category": "CI/CD 与 GitHub Actions",
    "core": "workflow YAML 是流水线的执行图描述文件，决定触发条件、执行环境、步骤顺序和失败行为。",
    "boundary": "把 YAML 当“配置抄模板”会造成隐性风险，例如触发事件错配、权限过大、步骤互相污染。",
    "signal": "新仓库接入自动化、或现有流水线行为不稳定时，通常都要回到 YAML 结构本身逐段核查。",
    "action": "按 `name/on/jobs` 三层组织；每个 job 固定 `runs-on`、显式列出 steps，并用 `if` 约束高风险步骤。",
    "aliases": []
  },
  {
    "id": "ci_trigger_events",
    "term": "触发事件 push/PR/schedule",
    "category": "CI/CD 与 GitHub Actions",
    "core": "触发事件决定“什么时候验证什么”：push 适合快速反馈，PR 适合合并门禁，schedule 适合周期巡检。",
    "boundary": "把所有检查都挂在 push 上会拖慢开发；把关键检查只挂在 schedule 上又会让问题滞后。",
    "signal": "当流水线耗时太长或检查覆盖不足时，往往是事件拆分策略没做好。",
    "action": "把快检放 `pull_request`，重检放 `schedule`，发布检查放 `workflow_dispatch`；每类任务单独 job。",
    "aliases": []
  },
  {
    "id": "ci_jobs_steps",
    "term": "Jobs 与 Steps",
    "category": "CI/CD 与 GitHub Actions",
    "core": "Job 是隔离执行单元，Step 是 job 内部动作；合理拆分能并行提速并降低失败定位成本。",
    "boundary": "把所有命令塞进一个 step 会导致日志难读、重试粒度粗、失败点不可见。",
    "signal": "当你只能看到“一坨脚本失败”，却不知道失败在安装、测试还是打包环节时，需要重构 jobs/steps。",
    "action": "按阶段拆成 `lint/test/build` 三个 job；每个 step 只做一件事，命名写清输入和输出。",
    "aliases": []
  },
  {
    "id": "ci_env_secrets",
    "term": "环境变量与 Secrets",
    "category": "CI/CD 与 GitHub Actions",
    "core": "环境变量承载非敏感配置，Secrets 承载密钥；两者分离是 CI 安全和可维护性的底线。",
    "boundary": "把 token 写进仓库或日志是高危行为，常见于临时排障时“先跑通再说”。",
    "signal": "当 workflow 需要访问外部服务（云、包仓、Webhook）时，必须先设计密钥注入路径。",
    "action": "在 GitHub 仓库设置 Secrets，通过 `${{ secrets.NAME }}` 注入；日志里对敏感值打码并最小化权限。",
    "aliases": []
  },
  {
    "id": "ci_artifacts_upload",
    "term": "构建产物上传",
    "category": "CI/CD 与 GitHub Actions",
    "core": "构建产物上传让“当时跑了什么”可追溯，尤其对测试报告、截图、二进制包和调试日志很关键。",
    "boundary": "只看控制台输出而不保存制品，复盘时会失去关键证据，排障成本陡增。",
    "signal": "当失败无法复现、或需要跨团队共享结果时，产物留存是第一优先项。",
    "action": "使用 `actions/upload-artifact` 保存测试报告和截图；失败分支也要上传，保留至少 7 天。",
    "aliases": []
  },
  {
    "id": "ci_matrix_strategy",
    "term": "矩阵策略",
    "category": "CI/CD 与 GitHub Actions",
    "core": "矩阵策略用于一次定义、多维验证，常见维度是 Python 版本、操作系统、数据库版本。",
    "boundary": "盲目扩矩阵会导致成本爆炸；维度太少又会漏掉兼容性缺陷。",
    "signal": "当用户环境多样且“只在某版本失败”频发时，矩阵是最有效的预防手段。",
    "action": "先覆盖主流组合（如 3.10/3.11 + ubuntu），稳定后再扩展；对慢用例启用 `fail-fast: false`。",
    "aliases": []
  },
  {
    "id": "ci_required_checks",
    "term": "Required Status Checks",
    "category": "CI/CD 与 GitHub Actions",
    "core": "Required Checks 把质量门禁制度化，避免“明知失败也能合并”破坏主干稳定性。",
    "boundary": "只靠口头约定无法替代强制检查，紧急合并会迅速侵蚀规范。",
    "signal": "当主分支经常红灯、团队对“能否合并”有争议时，需要把检查规则固化到分支保护策略。",
    "action": "在分支保护里勾选必过检查，至少包含 `lint` 和 `test`；禁用直接 push 到主分支。",
    "aliases": []
  },
  {
    "id": "ci_cache_deps",
    "term": "依赖缓存加速",
    "category": "CI/CD 与 GitHub Actions",
    "core": "依赖缓存通过复用包下载结果降低流水线时长，直接提升反馈速度和开发体验。",
    "boundary": "缓存键设计不当会引入脏缓存，导致“偶发通过/偶发失败”的幽灵问题。",
    "signal": "当安装依赖占据主要耗时，且 lock 文件更新不频繁时，优先引入缓存。",
    "action": "以 `hashFiles(\"**/requirements*.txt\")` 或 lock 文件作为 key；缓存命中后仍执行完整测试。",
    "aliases": []
  },
  {
    "id": "ci_cd_deploy",
    "term": "CD 自动部署概念",
    "category": "CI/CD 与 GitHub Actions",
    "core": "CD 关注“可控发布”，核心不是自动化本身，而是可回滚、可审计、可分阶段放量。",
    "boundary": "把“测试通过就直接全量上线”当 CD，忽略发布审批和回滚路径，会放大事故半径。",
    "signal": "当版本发布依赖人工 SSH 操作或多人口头确认时，说明需要把发布流程产品化。",
    "action": "先做 staging 自动部署 + 生产手动审批；发布后自动执行健康检查，失败立即触发回滚。",
    "aliases": []
  },
  {
    "id": "selenium_webdriver",
    "term": "WebDriver 基础",
    "category": "Selenium / UI 自动化",
    "core": "WebDriver 是浏览器自动化控制层，负责驱动页面打开、元素操作和状态读取。",
    "boundary": "把 UI 自动化当“脚本点点点”而不建稳定抽象，维护成本会持续攀升。",
    "signal": "需要验证真实用户路径（登录、下单、提交流程）时，WebDriver 才有价值。",
    "action": "统一初始化 driver、超时和窗口配置；测试结束确保 `quit()` 释放进程。",
    "aliases": []
  },
  {
    "id": "selenium_locators",
    "term": "定位器策略 CSS/XPath/ID",
    "category": "Selenium / UI 自动化",
    "core": "定位器策略决定用例稳定性，首选语义稳定的 id/data-testid，其次 CSS，最后才是脆弱 XPath。",
    "boundary": "依赖层级很深的 XPath，页面小改就全量失效。",
    "signal": "脚本经常报“找不到元素”时，问题通常不在点击逻辑而在定位器设计。",
    "action": "优先推动前端提供 `data-testid`；为关键元素建立集中式 locator 常量表。",
    "aliases": []
  },
  {
    "id": "selenium_explicit_wait",
    "term": "显式等待 WebDriverWait",
    "category": "Selenium / UI 自动化",
    "core": "显式等待按条件等待元素状态，能显著降低因异步渲染导致的假失败。",
    "boundary": "固定 `sleep` 既慢又不稳定，无法适应网络波动。",
    "signal": "偶发失败集中在页面加载和弹窗出现阶段时，应替换为显式等待。",
    "action": "使用 `WebDriverWait(driver, 10).until(...)` 等待“可见/可点击/文本出现”等条件。",
    "aliases": []
  },
  {
    "id": "selenium_implicit_wait",
    "term": "隐式等待与风险",
    "category": "Selenium / UI 自动化",
    "core": "隐式等待是全局查找超时设置，适合兜底，但过度依赖会掩盖性能与同步问题。",
    "boundary": "把隐式等待设太高会让每次失败都拖很久，诊断效率极低。",
    "signal": "测试运行时间异常增长时，要检查是否存在过大的 implicit wait。",
    "action": "隐式等待保持短值（如 1-2 秒），关键场景改用显式等待精确控制。",
    "aliases": []
  },
  {
    "id": "selenium_screenshots",
    "term": "失败截图策略",
    "category": "Selenium / UI 自动化",
    "core": "失败截图把“测试失败”变成可视证据，便于快速判断是 UI 变化还是脚本问题。",
    "boundary": "只保留报错堆栈不留截图，会增加跨团队沟通成本。",
    "signal": "CI 上复现困难的 UI 失败，第一手资料通常就是失败瞬间截图。",
    "action": "在异常钩子中自动 `save_screenshot`，文件名包含用例名和时间戳并上传 artifact。",
    "aliases": []
  },
  {
    "id": "selenium_page_object",
    "term": "Page Object 模式",
    "category": "Selenium / UI 自动化",
    "core": "Page Object 把页面结构和操作封装为对象，减少用例层重复选择器和点击逻辑。",
    "boundary": "把断言和业务流程全塞进 Page Object 会让职责边界模糊。",
    "signal": "当多个测试反复操作同一页面且改动频繁时，应引入 POM。",
    "action": "页面类只暴露“意图级方法”（如 `login_as`），断言放在测试层保持可读性。",
    "aliases": []
  },
  {
    "id": "selenium_headless",
    "term": "无头浏览器运行",
    "category": "Selenium / UI 自动化",
    "core": "无头模式适合 CI 环境自动执行，节省资源并便于容器化运行。",
    "boundary": "本地调试也强制 headless 会丢失可视观察能力。",
    "signal": "流水线环境无图形界面时，必须验证 headless 兼容性。",
    "action": "CI 使用 `--headless=new`；本地复现失败时切回有头模式并录屏。",
    "aliases": []
  },
  {
    "id": "selenium_test_pyramid",
    "term": "测试金字塔与 UI 测试定位",
    "category": "Selenium / UI 自动化",
    "core": "测试金字塔强调 UI 用例只覆盖关键路径，大量逻辑应由单元和接口测试承担。",
    "boundary": "把所有测试都堆在 UI 层会慢且脆，反馈周期不可接受。",
    "signal": "UI 套件越来越慢、失败越来越随机时，说明金字塔倒置了。",
    "action": "保留少量端到端烟测，把规则校验下沉到 API/单测；按风险分层安排执行频率。",
    "aliases": []
  },
  {
    "id": "llm_api_key_mgmt",
    "term": "API Key 安全管理",
    "category": "LLM API 实操",
    "core": "API Key 管理的重点是“最小暴露、可轮换、可追踪”，否则模型能力越强风险越大。",
    "boundary": "把 key 写进仓库、截图或共享文档，会在短时间内演变成真实安全事件。",
    "signal": "项目从本地 PoC 走向团队协作时，必须先补密钥治理。",
    "action": "用环境变量和密钥管理服务注入 key；按月轮换，异常调用量触发自动告警。",
    "aliases": []
  },
  {
    "id": "llm_token_pricing",
    "term": "Token 计费与成本控制",
    "category": "LLM API 实操",
    "core": "Token 成本控制是 LLM 产品化的财务底座，输入长度、输出上限和调用频次都会放大费用。",
    "boundary": "只关注效果不计成本，常见结果是 demo 可行、上线不可持续。",
    "signal": "当请求量增长或出现长上下文场景时，必须把单请求成本可视化。",
    "action": "记录每次调用的 input/output token，按功能模块打账；对长文本先摘要再推理。",
    "aliases": []
  },
  {
    "id": "llm_context_window",
    "term": "上下文窗口限制",
    "category": "LLM API 实操",
    "core": "上下文窗口限制决定模型一次能“看见”多少信息，超限会截断、报错或丢关键信息。",
    "boundary": "把全文硬塞进 prompt 会让真正重要的指令被稀释。",
    "signal": "模型开始答非所问、遗漏尾部信息或偶发 400 错误时，要先检查上下文预算。",
    "action": "实施分块检索 + 分层摘要；把系统约束放在最前，示例和背景按优先级裁剪。",
    "aliases": []
  },
  {
    "id": "llm_temperature",
    "term": "temperature 参数",
    "category": "LLM API 实操",
    "core": "temperature 控制采样随机性：越低越稳定，越高越发散，适合不同任务目标。",
    "boundary": "把高温度用于结构化抽取会显著降低一致性和可测性。",
    "signal": "输出风格漂移、字段不稳定时，优先调低 temperature 再看 prompt。",
    "action": "抽取/分类任务设 0~0.3，创意生成设 0.7 左右；固定参数后再做效果对比。",
    "aliases": []
  },
  {
    "id": "llm_system_prompt",
    "term": "system prompt 设计",
    "category": "LLM API 实操",
    "core": "system prompt 决定模型角色边界和行为优先级，是稳定输出格式与安全策略的核心控制点。",
    "boundary": "只写用户提问不写系统约束，会导致模型在不同输入下行为飘忽。",
    "signal": "当你需要“长期稳定同一种输出格式”时，必须把规则放入 system 层。",
    "action": "system 中明确角色、禁止项、输出 schema；用户层只放任务变量，减少规则冲突。",
    "aliases": []
  },
  {
    "id": "llm_few_shot",
    "term": "Few-shot 示例引导",
    "category": "LLM API 实操",
    "core": "Few-shot 通过高质量示例给模型“对齐样本”，比抽象描述更容易稳定任务行为。",
    "boundary": "示例质量差或风格不一致，会把噪声放大成系统性误差。",
    "signal": "零样本结果能用但不稳定时，通常加 2~3 个标准样例即可显著提升一致性。",
    "action": "挑选边界清晰、覆盖反例的示例；每次只改一组样例并做 A/B 评估。",
    "aliases": []
  },
  {
    "id": "llm_streaming",
    "term": "流式响应 Streaming",
    "category": "LLM API 实操",
    "core": "流式响应把“等待完整结果”改为“边生成边消费”，可明显降低首字延迟。",
    "boundary": "只追求流式体验却不处理中断和拼接，会导致前端展示残缺文本。",
    "signal": "对话产品需要即时反馈、或长文本生成等待过长时，应开启 streaming。",
    "action": "客户端按增量 token 拼接并维护光标；连接中断时支持重试与断点续传。",
    "aliases": []
  },
  {
    "id": "llm_rate_limit_api",
    "term": "API 调用频率限制",
    "category": "LLM API 实操",
    "core": "频率限制管理是稳定调用的前提，核心是识别 429 并实施有界退避。",
    "boundary": "收到 429 立即无脑重试会形成雪崩，反而延长整体恢复时间。",
    "signal": "并发上升后偶发超时或限流报错，说明需要引入请求队列和重试预算。",
    "action": "实现指数退避 + 抖动，设置最大重试次数；对热点任务启用令牌桶限速。",
    "aliases": []
  },
  {
    "id": "llm_error_handling",
    "term": "API 错误处理",
    "category": "LLM API 实操",
    "core": "LLM API 错误处理要区分参数错误、鉴权错误、限流错误和服务端错误，处理策略完全不同。",
    "boundary": "把所有异常都捕获成“调用失败”会丢失可操作信息。",
    "signal": "线上出现间歇性失败但日志只写一行报错时，先补错误分类与结构化日志。",
    "action": "按 HTTP 状态码分类处理；日志记录 request_id、模型名、token 用量和重试次数。",
    "aliases": []
  },
  {
    "id": "llm_eval_output",
    "term": "输出质量评估",
    "category": "LLM API 实操",
    "core": "输出评估不是“感觉好不好”，而是用可重复指标验证准确率、一致性和格式遵循度。",
    "boundary": "没有基准集就频繁改 prompt，团队会陷入主观争论。",
    "signal": "需求变更后需要证明“新版本确实更好”时，必须依赖评估集和评分规则。",
    "action": "建立回归样本集，定义评分 rubric；每次改动跑离线评测并记录版本对比。",
    "aliases": []
  },
  {
    "id": "docker_image_container",
    "term": "镜像与容器",
    "category": "Docker 容器基础",
    "core": "镜像是可分发的只读运行模板，容器是镜像的运行实例；两者分清后排障才不会混淆“构建问题”和“运行问题”。",
    "boundary": "把容器当虚拟机使用、在容器里手工改配置，最终会导致环境不可复现。",
    "signal": "当同一服务在不同机器行为不一致时，通常先确认镜像版本和容器启动参数。",
    "action": "用 `docker image ls` 看镜像版本，用 `docker ps -a` 查容器状态；固定 tag 并记录启动命令。",
    "aliases": []
  },
  {
    "id": "docker_dockerfile",
    "term": "Dockerfile 编写",
    "category": "Docker 容器基础",
    "core": "Dockerfile 定义了应用运行环境的构建步骤，是“环境即代码”的核心载体。",
    "boundary": "把临时调试命令塞进 Dockerfile 会放大镜像体积并污染生产环境。",
    "signal": "当新成员拉代码后无法复现环境，说明 Dockerfile 还没覆盖真实依赖。",
    "action": "采用分层写法：先基础镜像、再依赖、最后拷贝业务代码；把 `CMD/ENTRYPOINT` 写成单一职责。",
    "aliases": []
  },
  {
    "id": "docker_build_run",
    "term": "docker build / run",
    "category": "Docker 容器基础",
    "core": "`build` 负责产出可复用镜像，`run` 负责带参数启动实例，二者分离便于定位问题阶段。",
    "boundary": "“能跑就行”但不打 tag、不记录参数，会让回滚和对比失去依据。",
    "signal": "当上线后出现行为差异，需要快速回答“到底跑的是哪一个构建产物”。",
    "action": "执行 `docker build -t app:2026-02-22 .` 后用 `docker run --rm -p 8080:8080 app:2026-02-22` 验证。",
    "aliases": []
  },
  {
    "id": "docker_volume",
    "term": "数据卷 Volume",
    "category": "Docker 容器基础",
    "core": "Volume 用于把数据生命周期从容器进程中解耦，避免容器重建导致状态丢失。",
    "boundary": "把数据库数据写在容器层会在重启或替换容器时直接丢失。",
    "signal": "当服务需要持久化文件、缓存或数据库目录时，必须先设计挂载策略。",
    "action": "把数据目录挂到命名卷，例如 `-v app_data:/var/lib/app`；备份和恢复都基于卷路径执行。",
    "aliases": []
  },
  {
    "id": "docker_compose",
    "term": "Docker Compose 编排",
    "category": "Docker 容器基础",
    "core": "Compose 用声明式文件描述多容器依赖关系，让“本地一键起整套系统”成为常规能力。",
    "boundary": "依赖关系靠口头约定会导致启动顺序混乱、环境变量不一致。",
    "signal": "当服务数量超过 2 个（应用、数据库、缓存）且每次启动命令都很长时，应引入 Compose。",
    "action": "在 `compose.yml` 定义 `services/ports/volumes/env`，用 `docker compose up -d` 启动并用 `docker compose logs -f` 验证。",
    "aliases": []
  },
  {
    "id": "telegram_bot_api",
    "term": "Telegram Bot API 基础",
    "category": "推送与通知",
    "core": "Telegram Bot API 提供标准化消息交互能力，是快速搭建通知机器人最常用入口。",
    "boundary": "把机器人当群发工具而不做权限控制，会引发误发和滥用。",
    "signal": "当你需要把任务状态推送到即时通讯工具时，Telegram API 可快速落地。",
    "action": "先用 `getMe` 验证 token，再用测试 chat_id 发送一条最小消息确认链路通。",
    "aliases": []
  },
  {
    "id": "telegram_send_message",
    "term": "sendMessage 接口",
    "category": "推送与通知",
    "core": "`sendMessage` 是最基础发送接口，关键在于 chat_id 正确、格式可读、失败可重试。",
    "boundary": "消息模板随意拼接会导致关键信息缺失，值班人员难以判断优先级。",
    "signal": "告警、日报、任务完成通知等文本场景优先使用 sendMessage。",
    "action": "统一模板包含标题、摘要、链接、时间；发送失败按 429/5xx 区分退避策略。",
    "aliases": []
  },
  {
    "id": "telegram_bot_token",
    "term": "Bot Token 管理",
    "category": "推送与通知",
    "core": "Bot Token 等同机器人控制权，管理原则应与生产密钥一致严格。",
    "boundary": "把 token 放进代码仓库或聊天记录，会被自动扫描并滥用。",
    "signal": "机器人首次上线和成员扩充阶段最容易发生 token 泄露。",
    "action": "token 存储在密钥管理系统，泄露后立即 rotate 并审查近 7 天调用日志。",
    "aliases": []
  },
  {
    "id": "telegram_group_dm",
    "term": "群组与私信差异",
    "category": "推送与通知",
    "core": "群组与私信的 chat_id、权限模型和消息噪声特征不同，发送策略应分开设计。",
    "boundary": "把高频告警直接推送大群，容易造成信息淹没和告警疲劳。",
    "signal": "设计通知分层（个人值班 vs 团队广播）时，需先区分群聊和私聊通道。",
    "action": "高优先级直达值班私聊，汇总类信息发群组；在消息中注明级别与处理人。",
    "aliases": []
  },
  {
    "id": "email_smtplib",
    "term": "Python smtplib 发邮件",
    "category": "推送与通知",
    "core": "smtplib 适合正式通知和留档场景，可作为 IM 失败时的补充通道。",
    "boundary": "只依赖单一通道，一旦被限流或网络阻断会失去告警能力。",
    "signal": "需要对外部客户或管理层发送结构化报告时，邮件仍是主力渠道。",
    "action": "封装统一发信函数，支持纯文本+HTML；发送后记录 message-id 便于追踪。",
    "aliases": []
  },
  {
    "id": "notify_message_template",
    "term": "消息模板设计",
    "category": "推送与通知",
    "core": "消息模板统一后，接收方能在 3 秒内判断“发生了什么、多严重、要做什么”。",
    "boundary": "通知内容冗长且无结构，会让值班人员错过关键动作。",
    "signal": "多系统共用通知渠道时，模板标准化是降低认知负担的关键。",
    "action": "模板固定字段：级别、系统、事件、影响、建议动作、链接；避免自由发挥。",
    "aliases": []
  },
  {
    "id": "notify_throttle",
    "term": "通知频率控制",
    "category": "推送与通知",
    "core": "通知节流通过聚合、去重和冷却窗口控制消息洪峰，保护响应效率。",
    "boundary": "每条错误都即时报送会导致告警风暴，最终无人处理。",
    "signal": "同类告警短时间爆发时，必须启用节流策略。",
    "action": "设置去重键和冷却时间；窗口内只发首条+汇总，窗口结束补发统计。",
    "aliases": []
  },
  {
    "id": "pandas_read_write",
    "term": "pandas 读写 CSV/Excel",
    "category": "数据处理扩展",
    "core": "pandas 读写能力让表格数据在 CSV/Excel 与 DataFrame 之间高效转换。",
    "boundary": "不指定 dtype 直接读数据，可能引入隐式类型错误。",
    "signal": "批量数据清洗和分析任务中，读写稳定性是第一环。",
    "action": "读取时显式指定关键列类型；写出时固定列顺序并设置 `index=False`。",
    "aliases": []
  },
  {
    "id": "pandas_filter_sort",
    "term": "pandas 筛选与排序",
    "category": "数据处理扩展",
    "core": "筛选与排序是数据定位基本功，直接影响分析结果可解释性。",
    "boundary": "链式操作过长不做中间检查，容易筛错数据却不自知。",
    "signal": "需要从大表里快速找出目标记录时，filter/sort 是高频操作。",
    "action": "每次筛选后先 `head()` 抽样验证，再做排序和后续聚合。",
    "aliases": []
  },
  {
    "id": "pandas_groupby",
    "term": "pandas 分组聚合",
    "category": "数据处理扩展",
    "core": "groupby 用于按维度聚合指标，是统计分析和报表生成核心操作。",
    "boundary": "聚合前不处理缺失值和异常值，统计结果会失真。",
    "signal": "当你需要按日期、渠道、用户分组看趋势时，groupby 是基础工具。",
    "action": "明确分组键和聚合函数，输出前重置索引并补字段含义说明。",
    "aliases": []
  },
  {
    "id": "openpyxl_basics",
    "term": "openpyxl 精细 Excel 处理",
    "category": "数据处理扩展",
    "core": "openpyxl 适合做单元格级 Excel 处理，如样式、公式、批注和模板填充。",
    "boundary": "把大规模数据处理都放在 openpyxl，会比 pandas 慢很多。",
    "signal": "需要保留原模板格式并批量填数时，openpyxl 优势明显。",
    "action": "先加载模板再写值，改动后另存新文件；关键单元格做回读校验。",
    "aliases": []
  },
  {
    "id": "json_schema_validate",
    "term": "JSON Schema 校验",
    "category": "数据处理扩展",
    "core": "JSON Schema 校验在入口阶段拦截结构错误，防止脏数据进入核心流程。",
    "boundary": "只在出错后补救，而不在入口校验，会把问题扩散到下游。",
    "signal": "接口输入字段不稳定、上游系统较多时，schema 校验尤为必要。",
    "action": "请求入站先跑 schema validate，失败返回明确错误路径和字段名。",
    "aliases": []
  },
  {
    "id": "regex_pattern",
    "term": "正则表达式在数据清洗中的应用",
    "category": "数据处理扩展",
    "core": "正则在清洗中适合提取格式稳定字段，如手机号、订单号、日期。",
    "boundary": "拿正则处理复杂层次结构文本会变得脆弱难维护。",
    "signal": "当字段分隔不规整但模式稳定时，正则是高效工具。",
    "action": "为每个核心正则保留正负样例测试，避免规则升级时误伤。",
    "aliases": []
  },
  {
    "id": "sql_basics",
    "term": "SQL 基础语句 SELECT/INSERT/UPDATE",
    "category": "数据处理扩展",
    "core": "SQL 基础语句让你在存储层直接完成查询、写入和更新，是数据工程通用语言。",
    "boundary": "没有 where 条件的更新语句风险极高。",
    "signal": "需要快速验证数据状态、定位异常记录时，SQL 往往比代码更直接。",
    "action": "先 `SELECT` 确认范围，再执行 `UPDATE/DELETE`；重要操作包裹事务。",
    "aliases": []
  },
  {
    "id": "data_pipeline_pattern",
    "term": "数据管道模式",
    "category": "数据处理扩展",
    "core": "数据管道模式把流程分成采集、转换、加载、校验等阶段，便于监控和扩展。",
    "boundary": "把所有逻辑揉成单脚本，故障定位和复用都会变差。",
    "signal": "流程复杂度上升或团队协作增强时，应尽快管道化。",
    "action": "每阶段定义输入输出契约和指标；失败时记录阶段名和重试策略。",
    "aliases": []
  },
  {
    "id": "requests_get_params",
    "term": "requests.get 与参数传递",
    "category": "requests 与采集实战",
    "core": "`requests.get` + `params` 能安全编码查询参数，避免手拼 URL 带来的转义和漏参问题。",
    "boundary": "字符串拼接查询串容易在空格、中文和特殊字符上出错。",
    "signal": "做搜索、分页、筛选类请求时，参数编码正确性直接影响结果。",
    "action": "用 `requests.get(url, params={...}, timeout=10)`；出错时打印 `response.url` 复核最终请求。",
    "aliases": []
  },
  {
    "id": "requests_post_json",
    "term": "requests.post 发 JSON",
    "category": "requests 与采集实战",
    "core": "`requests.post(json=...)` 会自动序列化并设置 JSON 头，适合提交结构化业务数据。",
    "boundary": "手动 `data=str(dict)` 常导致服务端解析失败。",
    "signal": "接口要求 JSON body 且字段较多时，优先使用 `json` 参数。",
    "action": "调用后先检查 `status_code`，再 `response.json()`；解析失败时落原文日志。",
    "aliases": []
  },
  {
    "id": "requests_session",
    "term": "Session 会话复用",
    "category": "requests 与采集实战",
    "core": "Session 会复用连接和 cookie，能降低请求开销并保持登录态。",
    "boundary": "跨任务复用同一 Session 而不清理状态，容易引入串数据问题。",
    "signal": "需要连续请求同一站点或携带登录态抓取时，Session 是必备。",
    "action": "按任务创建独立 Session；任务结束显式 `close()`，避免长期连接泄漏。",
    "aliases": []
  },
  {
    "id": "requests_timeout_retry",
    "term": "requests 超时与重试实现",
    "category": "requests 与采集实战",
    "core": "超时与重试是采集稳定性的底线配置，目标是“快失败、可恢复”。",
    "boundary": "默认无限等待会让任务卡死，影响整条流水线。",
    "signal": "外部站点波动或网络抖动频繁时，必须配置 timeout + retry。",
    "action": "请求统一设置 `timeout=(3,10)`；对可重试错误用指数退避，超过上限进入失败队列。",
    "aliases": []
  },
  {
    "id": "requests_error_handling",
    "term": "requests 异常处理",
    "category": "requests 与采集实战",
    "core": "异常处理要区分网络错误、超时、状态码错误和解析错误，避免一刀切。",
    "boundary": "捕获大异常后静默跳过会导致数据缺口难以发现。",
    "signal": "采集任务“偶尔少数据”时，通常是错误被吞掉了。",
    "action": "分别捕获 `Timeout/ConnectionError/HTTPError`；记录 URL、参数、状态码和响应摘要。",
    "aliases": []
  },
  {
    "id": "bs4_find_select",
    "term": "BeautifulSoup find / select",
    "category": "requests 与采集实战",
    "core": "BeautifulSoup 的 `find/select` 分别适合结构明确和 CSS 查询场景，是 HTML 抽取核心工具。",
    "boundary": "仅靠脆弱层级选择器，页面轻微改版就会全量失效。",
    "signal": "从页面中抽标题、链接、价格等结构化字段时，通常先从 bs4 开始。",
    "action": "优先选择稳定属性（id/class/data-*）；抽取后立即做字段完整性校验。",
    "aliases": []
  },
  {
    "id": "pytest_assertion",
    "term": "pytest 断言与错误信息",
    "category": "测试与工程补充",
    "core": "pytest 断言应该直接表达业务期望，失败信息要能指导下一步修复。",
    "boundary": "断言写得过于抽象（如仅 `assert result`）会降低排障效率。",
    "signal": "测试失败后需要快速判断是数据问题还是逻辑问题时，断言质量尤为关键。",
    "action": "优先断言关键字段和边界值；必要时自定义失败消息补充上下文。",
    "aliases": []
  },
  {
    "id": "pytest_conftest",
    "term": "conftest.py 共享配置",
    "category": "测试与工程补充",
    "core": "conftest.py 用于共享 fixtures 和钩子，减少重复 setup 并统一测试基础设施。",
    "boundary": "把业务逻辑塞进 conftest 会让依赖关系隐蔽。",
    "signal": "测试文件增多后，重复初始化代码明显时应抽取到 conftest。",
    "action": "只放通用 fixture；按目录分层组织 conftest，避免全局污染。",
    "aliases": []
  },
  {
    "id": "pytest_test_discovery",
    "term": "测试发现机制",
    "category": "测试与工程补充",
    "core": "测试发现机制基于命名约定自动收集用例，影响“哪些测试会被执行”。",
    "boundary": "命名不规范会导致用例静默不执行。",
    "signal": "新增测试却在 CI 没跑到时，先检查 discovery 规则。",
    "action": "遵循 `test_*.py` 和 `test_*` 命名；定期执行 `pytest --collect-only` 审核收集结果。",
    "aliases": []
  },
  {
    "id": "pytest_run_select",
    "term": "运行与选择测试用例",
    "category": "测试与工程补充",
    "core": "用例选择执行可以提升调试效率，让你在改动集中区域快速获得反馈。",
    "boundary": "长期只跑局部测试不跑全量，会放大回归风险。",
    "signal": "本地迭代阶段需要快反馈，提交前需要全量回归。",
    "action": "开发中用 `-k` 和路径筛选，合并前执行全量 `pytest -q`。",
    "aliases": []
  },
  {
    "id": "json_loads_dumps",
    "term": "json.loads / json.dumps",
    "category": "测试与工程补充",
    "core": "`loads/dumps` 是字符串与对象互转基础，正确处理编码和类型能避免接口对接错误。",
    "boundary": "把 Python dict 直接转字符串发送，常导致 JSON 格式不合法。",
    "signal": "API 通信、配置读写、日志落盘都离不开 JSON 序列化。",
    "action": "始终用 `json.dumps` 生成 JSON；接收后先 `loads` 再做字段校验。",
    "aliases": []
  },
  {
    "id": "csv_dict_reader_writer",
    "term": "csv.DictReader / DictWriter",
    "category": "测试与工程补充",
    "core": "DictReader/DictWriter 按列名读写 CSV，降低字段顺序耦合。",
    "boundary": "依赖列位置而不依赖列名，模板一改顺序就错位。",
    "signal": "跨团队交换 CSV 或模板经常变动时，应改用 dict 方式读写。",
    "action": "写入前固定 `fieldnames` 并写 header；读取后先校验必需列是否存在。",
    "aliases": []
  },
  {
    "id": "logging_basic_config",
    "term": "logging.basicConfig 配置",
    "category": "测试与工程补充",
    "core": "basicConfig 是统一日志格式和级别的起点，影响后续排障效率。",
    "boundary": "到处 `print` 无法按级别过滤，也不利于集中收集。",
    "signal": "项目进入多模块协作后，日志规范必须先于复杂功能。",
    "action": "初始化统一日志格式（时间、级别、模块、消息），并按环境配置日志级别。",
    "aliases": []
  },
  {
    "id": "dotenv_usage",
    "term": "python-dotenv 使用",
    "category": "测试与工程补充",
    "core": "python-dotenv 让本地开发配置外置化，避免把密钥和环境差异写死在代码里。",
    "boundary": "把 `.env` 提交到仓库会造成凭据泄露风险。",
    "signal": "项目需要本地、测试、生产多环境切换时，dotenv 很实用。",
    "action": "项目启动时 `load_dotenv()`；仓库提供 `.env.example`，真实 `.env` 加入 `.gitignore`。",
    "aliases": []
  },
  {
    "id": "twelve_factor_config",
    "term": "12-Factor Config 原则",
    "category": "测试与工程补充",
    "core": "12-Factor 的 Config 原则强调配置来自环境而非代码，提升部署一致性和可移植性。",
    "boundary": "把环境差异写在 if/else 代码中，会让发布流程脆弱。",
    "signal": "应用需要跨机器或容器部署时，配置外部化是硬要求。",
    "action": "把数据库、密钥、服务地址全部改成环境变量注入，并在启动时做缺失检查。",
    "aliases": []
  },
  {
    "id": "shell_basics",
    "term": "Shell 基础命令",
    "category": "测试与工程补充",
    "core": "Shell 基础命令通过管道组合快速完成检索、过滤、统计，是工程排障提效利器。",
    "boundary": "完全依赖 GUI 点击会降低自动化和批处理能力。",
    "signal": "处理日志、文件批量操作、临时排障时，Shell 往往比写脚本更快。",
    "action": "熟练使用 `rg`、`awk`、`sort`、`uniq`、重定向和管道，并把常用命令沉淀成脚本。",
    "aliases": []
  },
  {
    "id": "n8n_trigger_webhook",
    "term": "Webhook Trigger",
    "category": "n8n 工作流",
    "core": "Webhook Trigger 节点负责接收并标准化外部事件，是事件驱动工作流的入口门面。",
    "boundary": "不校验来源和字段完整性会把脏数据直接带入下游。",
    "signal": "多系统联动且需要低延迟响应时，Webhook Trigger 是首选触发器。",
    "action": "入口先做 schema 校验和幂等键检查；无效请求直接返回明确错误码。",
    "aliases": []
  },
  {
    "id": "n8n_error_workflow",
    "term": "Error Workflow",
    "category": "n8n 工作流",
    "core": "独立 Error Workflow 可以把失败处理做成产品能力，而不是每条主流程都重复写一遍。",
    "boundary": "把错误处理散落在各节点，后续统一升级非常困难。",
    "signal": "流程数量增长后，错误治理需要从“节点级”提升到“平台级”。",
    "action": "统一错误模板：错误类型、节点名、输入摘要、执行链接、建议动作；集中发送到通知渠道。",
    "aliases": []
  },
  {
    "id": "n8n_credentials_mgmt",
    "term": "Credentials 管理",
    "category": "n8n 工作流",
    "core": "Credentials 管理关注的不只是“能连上”，还包括权限最小化、审计和生命周期管理。",
    "boundary": "所有流程共用一个高权限账号，单点泄露会影响全局。",
    "signal": "当流程跨多个业务域时，应按系统和环境拆分凭据并做权限隔离。",
    "action": "为每类外部系统建立独立凭据；定期检查未使用凭据并回收。",
    "aliases": []
  },
  {
    "id": "n8n_execution_log",
    "term": "执行日志与重放",
    "category": "n8n 工作流",
    "core": "执行日志与重放机制让故障处理从猜测转为证据驱动，尤其适合偶发性问题。",
    "boundary": "只重试不分析日志会把错误反复放大。",
    "signal": "当某类失败难以本地复现时，应直接基于历史执行进行重放验证。",
    "action": "保存失败执行的输入快照；修复后先在同样输入上重放通过再恢复定时触发。",
    "aliases": []
  }
]
